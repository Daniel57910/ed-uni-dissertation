{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv awscli --quiet\n",
    "%pip install gym stable-baselines3[extra] awscli boto3 pqdm awscli --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 sync experiments s3://dissertation-data-dmiller/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 sync s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train rl_ready_data_conv/files_used_30/window_1/batched_train --delete"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load rl_constant.py\n",
    "FEATURE_COLUMNS = [\n",
    "    \n",
    "    \"user_count\",\n",
    "    \"project_count\",\n",
    "    \"country_count\", \n",
    "    \"date_hour_sin\", \n",
    "    \"date_hour_cos\",\n",
    "    \"date_minute_sin\",\n",
    "    \"date_minute_cos\",\n",
    "    \n",
    "    \"session_30_count\",\n",
    "    \"session_5_count\",\n",
    "    \"cum_session_event\",\n",
    "    \"cum_session_time\",\n",
    "    \"expanding_click_average\",\n",
    "   \n",
    "    \"cum_platform_time\",\n",
    "    \"cum_platform_event\",\n",
    "    \"cum_projects\",\n",
    "    \"average_event_time\",\n",
    "    \"delta_last_event\",\n",
    "    \n",
    "    \"rolling_session_time\",\n",
    "    \"rolling_session_events\",\n",
    "    \"rolling_session_gap\",\n",
    "    \"previous_session_time\",\n",
    "    \"previous_session_events\",\n",
    "]\n",
    "\n",
    "\n",
    "METADATA = [\n",
    "    \"user_id\",\n",
    "    \"session_30_count_raw\",\n",
    "    \"cum_platform_event_raw\",\n",
    "    \"cum_platform_time_raw\",\n",
    "    \"cum_session_time_raw\",\n",
    "    \"cum_session_event_raw\",\n",
    "    \"date_time\"\n",
    "]\n",
    "\n",
    "RL_STAT_COLS = [\n",
    "    'session_size',\n",
    "    'session_minutes',\n",
    "    'size_cutoff',\n",
    "    'time_cutoff',\n",
    "    'reward'\n",
    "]\n",
    "\n",
    "PREDICTION_COLS = [\n",
    "    \"label\",\n",
    "    \"pred\"\n",
    "]\n",
    "\n",
    "LOAD_COLS = list(set(FEATURE_COLUMNS + METADATA + RL_STAT_COLS + PREDICTION_COLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load environment\n",
    "# %load environment\n",
    "import gym\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "MAX_EVAL_SIZE = 75\n",
    "\n",
    "class CitizenScienceEnv(gym.Env):\n",
    "    \n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, dataset, out_features, n_sequences, evaluation=False):\n",
    "        \"\"\"\n",
    "        trajectories: dictionary of user_id to their respective trajectories.\n",
    "        n_sequences: number of sequences used for preprocessing.\n",
    "        n_features: number of features used for preprocessing.\n",
    "        \"\"\"\n",
    "        super(CitizenScienceEnv, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.unique_sessions = self.dataset[['user_id', 'session_30_count_raw']].drop_duplicates()\n",
    "        self.n_sequences = n_sequences\n",
    "        self.current_session = None\n",
    "        self.current_session_index = 0\n",
    "        self.reward = 0\n",
    "        self.n_sequences = n_sequences\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        max_session_size = self.dataset['session_size'].max()\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space = gym.spaces.Box(low=-1, high=max_session_size, shape=(len(out_features) + 3, n_sequences + 1), dtype=np.float32)\n",
    "        self.evalution = evaluation\n",
    "        self.episode_bins = []\n",
    "        self.exp_runs = 0\n",
    "\n",
    "    def reset(self):\n",
    "        random_session = np.random.randint(0, self.unique_sessions.shape[0])\n",
    "        \n",
    "        user_to_run, session_to_run = self.unique_sessions.iloc[random_session][['user_id', 'session_30_count_raw']]\n",
    "        self.current_session = self._get_events(user_to_run, session_to_run)\n",
    "        self.metadata = self._metadata()\n",
    "        self.current_session_index = 1\n",
    "        self.reward = 0\n",
    "        return self._state()\n",
    "    \n",
    "    def _row_to_dict(self, metadata):\n",
    "        \"\"\"\n",
    "        Convert a row of metadata to a dictionary.\n",
    "        \"\"\"\n",
    "        return metadata.to_dict()\n",
    "    \n",
    "    def _reward_exp(self, cum_session_event_raw):\n",
    "        \"\"\"\n",
    "        Reward shaping as\n",
    "            0 if cum_session_event_raw < size_cutoff\n",
    "            (cum_session_event_raw - size_cutoff) * (cum_session_event_raw / size_cutoff) otherwise\n",
    "        \"\"\"\n",
    "        if cum_session_event_raw <= self.metadata['size_cutoff']:\n",
    "            return cum_session_event_raw / self.metadata['size_cutoff']\n",
    "        \n",
    "        return (cum_session_event_raw - self.metadata['size_cutoff']) * (cum_session_event_raw / self.metadata['size_cutoff'])\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        self._take_action(action)\n",
    "            \n",
    "        next_state, done, meta = self._calculate_next_state()\n",
    "        \n",
    "        \n",
    "        if done:\n",
    "            current_session_index = self.current_session_index if \\\n",
    "                self.current_session_index != self.current_session.shape[0] else self.current_session.shape[0] - 1\n",
    "            \n",
    "            self.exp_runs += 1\n",
    "            self.metadata['ended_event'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            self.metadata['ended_time'] = self.current_session.iloc[current_session_index]['cum_session_time_raw']\n",
    "            self.metadata['exp_runs'] = self.exp_runs\n",
    "            self.episode_bins.append(self._row_to_dict(self.metadata))\n",
    "            \n",
    "            self.metadata['ended_event'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            self.metadata['ended_time'] = self.current_session.iloc[current_session_index]['cum_session_time_raw']\n",
    "            self.metadata['exp_runs'] = self.exp_runs\n",
    "            self.episode_bins.append(self._row_to_dict(self.metadata))\n",
    "           \n",
    "            cum_session_event_raw = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            reward_exp = self._reward_exp(cum_session_event_raw)\n",
    "            \n",
    "            return next_state, reward_exp , done, {}\n",
    "        else:\n",
    "            self.reward = self.current_session.iloc[self.current_session_index]['cum_session_event_raw']\n",
    "            cum_session_event_raw = self.current_session.iloc[self.current_session_index]['cum_session_event_raw']\n",
    "            \n",
    "            reward_exp = self._reward_exp(cum_session_event_raw)\n",
    "    \n",
    "            self.current_session_index += 1        \n",
    "            \n",
    "            return next_state, reward_exp, done, meta\n",
    "    \n",
    "    def _metadata(self):\n",
    "        session_metadata = self.current_session.iloc[0][RL_STAT_COLS].copy()\n",
    "        session_metadata['ended'] = 0\n",
    "        for meta_col in ['small', 'medium', 'large']:\n",
    "            session_metadata[f'inc_{meta_col}'] = 0\n",
    "            session_metadata[f'time_{meta_col}'] = 0\n",
    "\n",
    "        return session_metadata\n",
    "    \n",
    "    def flush_episode_bins(self):\n",
    "        episode_bins = self.episode_bins.copy()\n",
    "        self.episode_bins = []\n",
    "        return episode_bins\n",
    "    \n",
    "    def _calculate_next_state(self):\n",
    "        \n",
    "        if (self.current_session_index == self.current_session.shape[0]):\n",
    "            return None, True, {}\n",
    "\n",
    "        if self._continuing_in_session():\n",
    "            return self._state(), False, {}\n",
    "    \n",
    "        return None, True, {}\n",
    "         \n",
    "    def _continuing_in_session(self):\n",
    "        event_cutoff = self.current_session.iloc[self.current_session_index]['size_cutoff']\n",
    "        current_session_event = self.current_session.iloc[self.current_session_index]['cum_session_event_raw']\n",
    "        if current_session_event <= event_cutoff or current_session_event  >= MAX_EVAL_SIZE:\n",
    "            return True\n",
    "    \n",
    "        extending_low = self._probability_extending(current_session_event, self.metadata['inc_small']) - \\\n",
    "            (0.05 + np.random.normal(-0.02, 0.1, 100).mean())\n",
    "\n",
    "            \n",
    "        extending_medium = self._probability_extending(current_session_event, self.metadata['inc_medium']) - \\\n",
    "            (0.1 + np.random.normal(-0.02, 0.1, 100).mean()) \n",
    "            \n",
    "        extending_large = self._probability_extending(current_session_event, self.metadata['inc_large']) + \\\n",
    "            (0.2 + np.random.normal(-0.02, 0.1, 100).mean())\n",
    "            \n",
    "        return any([\n",
    "            extending_low > 0.4 and extending_low <= 0.75,\n",
    "            extending_medium > 0.4 and extending_medium <= 0.75,\n",
    "            extending_large > 0.4 and extending_large <= 0.75\n",
    "        ])\n",
    "        \n",
    "           \n",
    "    \n",
    "    def _probability_extending(self, current_session_event, incentive_event):\n",
    "        if incentive_event == 0:\n",
    "            return 0\n",
    "         \n",
    "        continue_session = norm(\n",
    "            loc=max(incentive_event, 1),\n",
    "            scale=max(incentive_event *.75, 1)\n",
    "        ).cdf(max(current_session_event, 1)) \n",
    "        \n",
    "        return continue_session\n",
    "        \n",
    "\n",
    "    def _get_events(self, user_id, session):\n",
    "        subset = self.dataset[\n",
    "            (self.dataset['user_id'] == user_id) &\n",
    "            (self.dataset['session_30_count_raw'] == session).copy()\n",
    "        ]\n",
    "\n",
    "        subset = subset.sort_values(by=['date_time'])\n",
    "        return subset\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "        if action == 0:\n",
    "            return 1\n",
    "        \n",
    "        current_session_index = self.current_session_index if \\\n",
    "            self.current_session_index != self.current_session.shape[0] else self.current_session.shape[0] - 1\n",
    "    \n",
    "        if action == 1:\n",
    "            if self.metadata['inc_small'] > 0:\n",
    "                return 1\n",
    "\n",
    "            self.metadata['inc_small'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            self.metadata['time_small'] = self.current_session.iloc[current_session_index]['cum_session_time_raw']\n",
    "            return 1\n",
    "    \n",
    "        elif action == 2:\n",
    "            if self.metadata['inc_medium'] > 0:\n",
    "                return 1\n",
    "            self.metadata['inc_medium'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            self.metadata['time_medium'] = self.current_session.iloc[current_session_index]['cum_session_time_raw']\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            if self.metadata['inc_large'] > 0:\n",
    "                return 1\n",
    "            self.metadata['inc_large'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            self.metadata['time_large'] = self.current_session.iloc[current_session_index]['cum_session_time_raw']\n",
    "            return 1\n",
    "\n",
    "    def _state(self):\n",
    "\n",
    "        if self.current_session_index > self.n_sequences:\n",
    "            events = self.current_session.iloc[self.current_session_index - (self.n_sequences + 1):self.current_session_index][self.out_features]\n",
    "            events['inc_small'] = self.metadata['inc_small']\n",
    "            events['inc_medium'] = self.metadata['inc_medium']\n",
    "            events['inc_large'] = self.metadata['inc_large']\n",
    "            \n",
    "            events = events.values\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            delta = min((self.n_sequences + 1)- self.current_session_index, self.n_sequences)\n",
    "            zero_cat = np.zeros((delta, len(self.out_features) + 3))\n",
    "            events = self.current_session.iloc[:max(self.current_session_index, 1)][self.out_features]\n",
    "            \n",
    "            events['inc_small'] = self.metadata['inc_small']\n",
    "            events['inc_medium'] = self.metadata['inc_medium']\n",
    "            events['inc_large'] = self.metadata['inc_large']\n",
    "            \n",
    "            \n",
    "            events = np.concatenate((zero_cat, events), axis=0)\n",
    "        \n",
    "        return events.astype(np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load callback\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import TensorBoardOutputFormat\n",
    "from datetime import datetime\n",
    "\n",
    "class DistributionCallback(BaseCallback):\n",
    "    \n",
    "    @classmethod\n",
    "    def tensorboard_setup(cls, log_dir, log_freq):\n",
    "        cls._log_dir = log_dir\n",
    "        cls._log_freq = log_freq\n",
    "\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self._log_freq == 0:\n",
    "            dist_list = self.training_env.env_method('flush_episode_bins')\n",
    "            values_to_log = [item for sublist in dist_list for item in sublist if len(sublist) > 0]\n",
    "\n",
    "            values_df = pd.DataFrame(\n",
    "                values_to_log\n",
    "            )\n",
    "            \n",
    "            \n",
    "            session_size, size_cutoff, session_minutes, time_cutoff, ended_event, ended_time = (\n",
    "                values_df['session_size'].mean(),\n",
    "                values_df['size_cutoff'].mean(),\n",
    "                values_df['session_minutes'].mean(),\n",
    "                values_df['time_cutoff'].mean(),\n",
    "                values_df['ended_event'].mean(),\n",
    "                values_df['ended_time'].mean(),\n",
    "            )\n",
    "            \n",
    "            inc_index_small, inc_index_medium, inc_index_large = (\n",
    "                values_df['inc_small'].mean(),\n",
    "                values_df['inc_medium'].mean(),\n",
    "                values_df['inc_large'].mean()\n",
    "            )\n",
    "            \n",
    "            time_minutes_small, time_minutes_medium, time_minutes_large = (\n",
    "                values_df['time_small'].mean(),\n",
    "                values_df['time_medium'].mean(),\n",
    "                values_df['time_large'].mean()\n",
    "            )\n",
    "            \n",
    "            size_stats = {\n",
    "                'session_size': session_size,\n",
    "                'size_cutoff': size_cutoff,\n",
    "                'ended_size': ended_event,\n",
    "                'inc_small': inc_index_small,\n",
    "                'inc_medium': inc_index_medium,\n",
    "                'inc_large': inc_index_large,\n",
    "            }\n",
    "            \n",
    "            \n",
    "            time_stats = {\n",
    "                'session_minutes': session_minutes,\n",
    "                'time_cutoff': time_cutoff,\n",
    "                'ended_time': ended_time,\n",
    "                'time_small': time_minutes_small,\n",
    "                'time_medium': time_minutes_medium,\n",
    "                'time_large': time_minutes_large,\n",
    "            }\n",
    "            \n",
    "            for key, value in size_stats.items():\n",
    "                self.logger.record(f'size/{key}', value)\n",
    "            \n",
    "            for key, value in time_stats.items():\n",
    "                self.logger.record(f'sess_time/{key}', value)\n",
    "                \n",
    "            values_df.to_csv(f'{self._log_dir}/{self.n_calls // self._log_freq}.csv')\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load policies/cnn_policy\n",
    "\n",
    "from typing import Dict, List, Type, Union\n",
    "\n",
    "import gym\n",
    "import torch\n",
    "from gym import spaces\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.dqn.policies import DQNPolicy\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import logging\n",
    "global logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CustomConv1dFeatures(BaseFeaturesExtractor):\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_sequences_features(cls, n_sequences, n_features):\n",
    "        cls.n_sequences = n_sequences\n",
    "        cls.n_features = n_features\n",
    "        \n",
    "    \n",
    "    def __init__(self, observation_space: spaces.Box, features_dim=24):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        \n",
    "        \n",
    "        self.cnn_1 = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ELU()\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.conv_1_reshape = nn.Conv1d(\n",
    "            self.n_features,\n",
    "            self.n_features*2,\n",
    "            kernel_size=1,\n",
    "            padding=0\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.a_pool_1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.cnn_bottleneck_wide = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features*2, self.n_features*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*4),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*4, self.n_features*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*4),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*4, self.n_features*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*4),\n",
    "            nn.ELU()   \n",
    "        )\n",
    "        \n",
    "        self.conv_2_reshape = nn.Conv1d(\n",
    "            self.n_features*2,\n",
    "            self.n_features*4,\n",
    "            kernel_size=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.cnn_bottleneck_narrow = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features*4, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        self.conv_3_reshape = nn.Conv1d(\n",
    "            self.n_features*4,\n",
    "            self.n_features*2,\n",
    "            kernel_size=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features*2, self.n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features, self.n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features, self.n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        self.conv_4_reshape = nn.Conv1d(\n",
    "            self.n_features*2,\n",
    "            self.n_features,\n",
    "            kernel_size=1,\n",
    "            padding=0\n",
    "        )\n",
    "                \n",
    "        self.down_max = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features, self.n_features // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features // 2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features // 2, self.n_features // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features // 2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features // 2, self.n_features // 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features // 2),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.mpool_flat = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.down_max_reshape = nn.Conv1d(\n",
    "            self.n_features,\n",
    "            self.n_features // 2,\n",
    "            kernel_size=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sample_tensor = torch.zeros((1, self.n_features, self.n_sequences))\n",
    "            sample_tensor = self.cnn_1(sample_tensor) + self.conv_1_reshape(sample_tensor)\n",
    "            sample_tensor = self.a_pool_1(sample_tensor)\n",
    "            sample_tensor = self.cnn_bottleneck_wide(sample_tensor) + self.conv_2_reshape(sample_tensor)\n",
    "            sample_tensor = self.cnn_bottleneck_narrow(sample_tensor) + self.conv_3_reshape(sample_tensor)\n",
    "            sample_tensor = self.downsample(sample_tensor) + self.conv_4_reshape(sample_tensor)\n",
    "            sample_tensor = self.down_max(sample_tensor) + self.down_max_reshape(sample_tensor)\n",
    "            mpool_flat_out = self.mpool_flat(sample_tensor)\n",
    "            linear_in = mpool_flat_out.shape[1]\n",
    "            self.final_out_linear = nn.Sequential(\n",
    "\n",
    "                nn.Linear(linear_in, features_dim),\n",
    "                nn.ELU()\n",
    "            )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, obs):\n",
    "\n",
    "        \n",
    "        obs_cnn_1 = self.cnn_1(obs) + self.conv_1_reshape(obs)\n",
    "        \n",
    "        obs_cnn_1 = self.a_pool_1(obs_cnn_1)\n",
    "        \n",
    "        obs_cnn_2 = self.cnn_bottleneck_wide(obs_cnn_1) + self.conv_2_reshape(obs_cnn_1)\n",
    "        \n",
    "        obs_cnn_3 = self.cnn_bottleneck_narrow(obs_cnn_2) + self.conv_3_reshape(obs_cnn_2)\n",
    "        \n",
    "        obs_cnn_4 = self.downsample(obs_cnn_3) + self.conv_4_reshape(obs_cnn_3)\n",
    "       \n",
    "        obs_cnn_5 = self.down_max(obs_cnn_4) + self.down_max_reshape(obs_cnn_4)\n",
    "        \n",
    "        mpool_flat_out = self.mpool_flat(obs_cnn_5)\n",
    "        \n",
    "        return self.final_out_linear(mpool_flat_out)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load incentive_reinforcement_learning_cpu.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from pprint import pformat\n",
    "from typing import Callable\n",
    "import boto3\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "from stable_baselines3 import A2C, DQN, PPO\n",
    "from stable_baselines3.common.callbacks import (CallbackList,\n",
    "                                                CheckpointCallback,\n",
    "                                                StopTrainingOnMaxEpisodes)\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor, VecNormalize\n",
    "from stable_baselines3.dqn.policies import DQNPolicy\n",
    "\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from pprint import pformat\n",
    "from typing import Callable\n",
    "import boto3\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)\n",
    "np.set_printoptions(precision=4, linewidth=1000, suppress=True)\n",
    "torch.set_printoptions(precision=4, linewidth=500, sci_mode=False)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "global logger\n",
    "logger = logging.getLogger('rl_exp_train')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "S3_BASELINE_PATH = 's3://dissertation-data-dmiller/'\n",
    "N_SEQUENCES = 15\n",
    "CHECKPOINT_FREQ = 300_000\n",
    "TB_LOG = 10_000\n",
    "WINDOW = 1\n",
    "REWARD_CLIP = 90\n",
    "MIN_MAX_RANGE = (10, 90)\n",
    "\"\"\"\n",
    "Reward clip based on achieving maximum reward for 90 minute session at\n",
    "(s / 45) * (s - 45)\n",
    "\"\"\"\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func\n",
    "\n",
    "def parse_args():\n",
    "    parse = argparse.ArgumentParser()\n",
    "    parse.add_argument('--read_path', type=str, default='rl_ready_data_conv')\n",
    "    parse.add_argument('--n_files', type=int, default=2)\n",
    "    parse.add_argument('--n_episodes', type=int, default=10_000)\n",
    "    parse.add_argument('--lstm', type=str, default='label')\n",
    "    parse.add_argument('--part', type=str, default='train')\n",
    "    parse.add_argument('--feature_extractor', type=str, default='cnn') \n",
    "    args = parse.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def simplify_experiment(vectorized_df, clip_engagement=False):\n",
    "    vectorized_df = [\n",
    "        df[(df['session_size'] >= MIN_MAX_RANGE[0]) & (df['session_size'] <= MIN_MAX_RANGE[1])] for df in vectorized_df\n",
    "    ]\n",
    "    if clip_engagement:\n",
    "        vectorized_df_clip = []\n",
    "        for df in vectorized_df:\n",
    "            df['pred'] = df['pred'].apply(lambda x: 1 if x > .5 else 0)\n",
    "            vectorized_df_clip.append(df)\n",
    "        vectorized_df = vectorized_df_clip\n",
    "\n",
    "    return vectorized_df\n",
    "\n",
    "\n",
    "def main(args):\n",
    "   \n",
    "    \n",
    "    logger.info('Starting Incentive Reinforcement Learning')\n",
    "    logger.info(pformat(args.__dict__))\n",
    "    exec_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    \n",
    "    read_path, n_files, n_episodes, lstm, part, feature_ext, clip_engage = (\n",
    "        args.read_path, \n",
    "        args.n_files, \n",
    "        args.n_episodes, \n",
    "        args.lstm,\n",
    "        args.part,\n",
    "        args.feature_extractor,\n",
    "        args.clip_engagement\n",
    "    )\n",
    "\n",
    "    base_read_path = os.path.join(read_path, f'files_used_{n_files}', f'window_{WINDOW}', f'batched_{part}')\n",
    "    logger.info(f'Reading data from {base_read_path}')\n",
    "    files= os.listdir(base_read_path)\n",
    "    n_envs = len(files)\n",
    "    logger.info(f'Files found: {len(files)} for environment vectorization')\n",
    "\n",
    "\n",
    "    df_files = [\n",
    "        pd.read_parquet(os.path.join(base_read_path, file), columns=LOAD_COLS)\n",
    "        for file in files\n",
    "    ]\n",
    "   \n",
    "    df_files = simplify_experiment(df_files, clip_engagement=clip_engage)\n",
    "\n",
    "    n_envs = len(df_files)\n",
    "    \n",
    "    logger.info(f'Files used: {len(df_files)} for environment vectorization')\n",
    "    \n",
    "    out_features = FEATURE_COLUMNS + [lstm] if lstm else FEATURE_COLUMNS\n",
    "    \n",
    "    logger.info(f'Out features: {out_features}')\n",
    "\n",
    "    citizen_science_vec =DummyVecEnv([lambda: CitizenScienceEnv(vec_df, out_features, N_SEQUENCES) for vec_df in df_files])\n",
    "    # citizen_science_vec = VecNormalize(citizen_science_vec, norm_obs=False, norm_reward=True, clip_reward=REWARD_CLIP)\n",
    "\n",
    "    monitor_train = VecMonitor(citizen_science_vec)\n",
    "    \n",
    "    logger.info(f'Vectorized environments created')\n",
    "\n",
    "    base_exp_path = os.path.join('experiments', f'dqn_{lstm}_{feature_ext}/{exec_time}')\n",
    "\n",
    "\n",
    "    tensorboard_dir, checkpoint_dir = (\n",
    "        os.path.join(base_exp_path, 'training_metrics'),\n",
    "        os.path.join(base_exp_path, 'checkpoints')\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(tensorboard_dir):\n",
    "        logger.info(f'Creating directory {tensorboard_dir} for tensorboard logs')\n",
    "        os.makedirs(tensorboard_dir)\n",
    "   \n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        logger.info(f'Creating directory {checkpoint_dir} for checkpoints')\n",
    "        os.makedirs(checkpoint_dir) \n",
    "\n",
    "    checkpoint_freq = int(CHECKPOINT_FREQ // (n_envs // 2))\n",
    "    log_freq = int(TB_LOG // n_envs)\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=checkpoint_freq,\n",
    "        save_path=checkpoint_dir, \n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    DistributionCallback.tensorboard_setup(tensorboard_dir, (TB_LOG * 5) // n_envs)\n",
    "    logger_callback = DistributionCallback()\n",
    "    \n",
    "    callback_list = CallbackList([checkpoint_callback, logger_callback])\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    if feature_ext == 'cnn':\n",
    "        CustomConv1dFeatures.setup_sequences_features(N_SEQUENCES + 1, len(out_features) + 3)\n",
    "        logger.info('Using custom 1 dimensional CNN feature extractor')\n",
    "        policy_kwargs = dict(\n",
    "            features_extractor_class=CustomConv1dFeatures,\n",
    "            net_arch=[12],\n",
    "            normalize_images=False,\n",
    "            activation_fn=nn.ELU,\n",
    "            \n",
    "        )\n",
    "        model = DQN(\n",
    "            policy='CnnPolicy', \n",
    "            env=monitor_train, \n",
    "            verbose=1, \n",
    "            tensorboard_log=tensorboard_dir, \n",
    "            policy_kwargs=policy_kwargs, \n",
    "            device=device, \n",
    "            stats_window_size=1000)\n",
    "    else:\n",
    "        model = DQN(\n",
    "            policy='MlpPolicy', \n",
    "            env=monitor_train, \n",
    "            verbose=1, \n",
    "            tensorboard_log=tensorboard_dir, \n",
    "            policy_kwargs=dict(\n",
    "                activation_fn=nn.ELU,\n",
    "                normalize_images=False,\n",
    "            ),\n",
    "            device=device, \n",
    "            stats_window_size=1000\n",
    "        )\n",
    "        \n",
    "    logger.info(f'Model created: policy')\n",
    "    \n",
    "    logger.info(pformat(model.policy))\n",
    "        \n",
    "    logger.info(f'Beginning training') \n",
    "    \n",
    "            \n",
    "    logger.info(pformat([\n",
    "        'n_episodes: {}'.format(n_episodes),\n",
    "        'read_path: {}'.format(read_path),\n",
    "        'n_files: {}'.format(n_files),\n",
    "        'n_sequences: {}'.format(N_SEQUENCES),\n",
    "        'n_envs: {}'.format(n_envs),\n",
    "        'device: {}'.format(device),\n",
    "        'lstm: {}'.format(lstm),\n",
    "        'part: {}'.format(part),\n",
    "        'feature_extractor: {}'.format(feature_ext),\n",
    "        'tensorboard_dir: {}'.format(tensorboard_dir),\n",
    "        'checkpoint_dir: {}'.format(checkpoint_dir),\n",
    "        'checkpoint_freq: {}'.format(checkpoint_freq),\n",
    "        'tb_freq: {}'.format(log_freq),\n",
    "    ]))\n",
    "    \n",
    "\n",
    "    model.learn(total_timesteps=8_000_000, log_interval=log_freq, progress_bar=True, callback=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Argument:\n",
    "    read_path = 'rl_ready_data_conv'\n",
    "    n_files = 30\n",
    "    n_episodes = 600_000\n",
    "    lstm = 'pred'\n",
    "    part = 'train'\n",
    "    feature_extractor = 'cnn'\n",
    "    clip_engagement = False\n",
    "    # penalize_losses = True\n",
    "    # include_her = False\n",
    "    # upper_prob_bound = 0.75\n",
    "    # lower_prob_bound = 0.4\n",
    "    # large_inc_effect = .2\n",
    "    # mid_inc_effect = .1\n",
    "    # small_inc_effect = .05\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/16/2023 08:33:42 AM Starting Incentive Reinforcement Learning\n",
      "06/16/2023 08:33:42 AM mappingproxy({'__dict__': <attribute '__dict__' of 'Argument' objects>,\n",
      "              '__doc__': None,\n",
      "              '__module__': '__main__',\n",
      "              '__weakref__': <attribute '__weakref__' of 'Argument' objects>,\n",
      "              'clip_engagement': False,\n",
      "              'feature_extractor': 'cnn',\n",
      "              'lstm': 'pred',\n",
      "              'n_episodes': 600000,\n",
      "              'n_files': 30,\n",
      "              'part': 'train',\n",
      "              'read_path': 'rl_ready_data_conv'})\n",
      "06/16/2023 08:33:42 AM Reading data from rl_ready_data_conv/files_used_30/window_1/batched_train\n",
      "06/16/2023 08:33:42 AM Files found: 100 for environment vectorization\n",
      "06/16/2023 08:33:50 AM Files used: 100 for environment vectorization\n",
      "06/16/2023 08:33:50 AM Out features: ['user_count', 'project_count', 'country_count', 'date_hour_sin', 'date_hour_cos', 'date_minute_sin', 'date_minute_cos', 'session_30_count', 'session_5_count', 'cum_session_event', 'cum_session_time', 'expanding_click_average', 'cum_platform_time', 'cum_platform_event', 'cum_projects', 'average_event_time', 'delta_last_event', 'rolling_session_time', 'rolling_session_events', 'rolling_session_gap', 'previous_session_time', 'previous_session_events', 'pred']\n",
      "06/16/2023 08:33:51 AM Vectorized environments created\n",
      "06/16/2023 08:33:51 AM Creating directory experiments/dqn_pred_cnn/2023-06-16_08-33-42/training_metrics for tensorboard logs\n",
      "06/16/2023 08:33:51 AM Creating directory experiments/dqn_pred_cnn/2023-06-16_08-33-42/checkpoints for checkpoints\n",
      "06/16/2023 08:33:51 AM Using custom 1 dimensional CNN feature extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/16/2023 08:33:52 AM Model created: policy\n",
      "06/16/2023 08:33:52 AM CnnPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): CustomConv1dFeatures(\n",
      "      (cnn_1): Sequential(\n",
      "        (0): Conv1d(26, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_1_reshape): Conv1d(26, 52, kernel_size=(1,), stride=(1,))\n",
      "      (a_pool_1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "      (cnn_bottleneck_wide): Sequential(\n",
      "        (0): Conv1d(52, 104, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_2_reshape): Conv1d(52, 104, kernel_size=(1,), stride=(1,))\n",
      "      (cnn_bottleneck_narrow): Sequential(\n",
      "        (0): Conv1d(104, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_3_reshape): Conv1d(104, 52, kernel_size=(1,), stride=(1,))\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(52, 26, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_4_reshape): Conv1d(52, 26, kernel_size=(1,), stride=(1,))\n",
      "      (down_max): Sequential(\n",
      "        (0): Conv1d(26, 13, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(13, 13, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(13, 13, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (mpool_flat): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "      (down_max_reshape): Conv1d(26, 13, kernel_size=(1,), stride=(1,))\n",
      "      (final_out_linear): Sequential(\n",
      "        (0): Linear(in_features=52, out_features=24, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=12, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=12, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): CustomConv1dFeatures(\n",
      "      (cnn_1): Sequential(\n",
      "        (0): Conv1d(26, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_1_reshape): Conv1d(26, 52, kernel_size=(1,), stride=(1,))\n",
      "      (a_pool_1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "      (cnn_bottleneck_wide): Sequential(\n",
      "        (0): Conv1d(52, 104, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_2_reshape): Conv1d(52, 104, kernel_size=(1,), stride=(1,))\n",
      "      (cnn_bottleneck_narrow): Sequential(\n",
      "        (0): Conv1d(104, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_3_reshape): Conv1d(104, 52, kernel_size=(1,), stride=(1,))\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(52, 26, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (conv_4_reshape): Conv1d(52, 26, kernel_size=(1,), stride=(1,))\n",
      "      (down_max): Sequential(\n",
      "        (0): Conv1d(26, 13, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ELU(alpha=1.0)\n",
      "        (3): Conv1d(13, 13, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv1d(13, 13, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ELU(alpha=1.0)\n",
      "      )\n",
      "      (mpool_flat): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "      (down_max_reshape): Conv1d(26, 13, kernel_size=(1,), stride=(1,))\n",
      "      (final_out_linear): Sequential(\n",
      "        (0): Linear(in_features=52, out_features=24, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=12, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=12, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "06/16/2023 08:33:52 AM Beginning training\n",
      "06/16/2023 08:33:52 AM ['n_episodes: 600000',\n",
      " 'read_path: rl_ready_data_conv',\n",
      " 'n_files: 30',\n",
      " 'n_sequences: 15',\n",
      " 'n_envs: 100',\n",
      " 'device: cuda',\n",
      " 'lstm: pred',\n",
      " 'part: train',\n",
      " 'feature_extractor: cnn',\n",
      " 'tensorboard_dir: '\n",
      " 'experiments/dqn_pred_cnn/2023-06-16_08-33-42/training_metrics',\n",
      " 'checkpoint_dir: experiments/dqn_pred_cnn/2023-06-16_08-33-42/checkpoints',\n",
      " 'checkpoint_freq: 6000',\n",
      " 'tb_freq: 100']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to experiments/dqn_pred_cnn/2023-06-16_08-33-42/training_metrics/DQN_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5436ceee121042f6a667110878174309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 9.7       |\n",
      "|    ep_rew_mean      | 10.432504 |\n",
      "|    exploration_rate | 0.998     |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 279       |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 1800      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 11.8      |\n",
      "|    ep_rew_mean      | 12.074234 |\n",
      "|    exploration_rate | 0.996     |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 344       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 3300      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 12.5      |\n",
      "|    ep_rew_mean      | 12.729121 |\n",
      "|    exploration_rate | 0.994     |\n",
      "| time/               |           |\n",
      "|    episodes         | 300       |\n",
      "|    fps              | 378       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 4800      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 13.4      |\n",
      "|    ep_rew_mean      | 13.460727 |\n",
      "|    exploration_rate | 0.992     |\n",
      "| time/               |           |\n",
      "|    episodes         | 400       |\n",
      "|    fps              | 392       |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 6400      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 13.7      |\n",
      "|    ep_rew_mean      | 13.757271 |\n",
      "|    exploration_rate | 0.991     |\n",
      "| time/               |           |\n",
      "|    episodes         | 500       |\n",
      "|    fps              | 396       |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total_timesteps  | 7700      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.87847 |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 9200     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 13.8      |\n",
      "|    ep_rew_mean      | 13.929017 |\n",
      "|    exploration_rate | 0.988     |\n",
      "| time/               |           |\n",
      "|    episodes         | 700       |\n",
      "|    fps              | 398       |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total_timesteps  | 10500     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 13.8      |\n",
      "|    ep_rew_mean      | 14.111452 |\n",
      "|    exploration_rate | 0.986     |\n",
      "| time/               |           |\n",
      "|    episodes         | 800       |\n",
      "|    fps              | 403       |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total_timesteps  | 11900     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 13.7      |\n",
      "|    ep_rew_mean      | 14.019134 |\n",
      "|    exploration_rate | 0.984     |\n",
      "| time/               |           |\n",
      "|    episodes         | 900       |\n",
      "|    fps              | 405       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total_timesteps  | 13300     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/            |            |\n",
      "|    ep_len_mean      | 13.8       |\n",
      "|    ep_rew_mean      | 14.3615465 |\n",
      "|    exploration_rate | 0.983      |\n",
      "| time/               |            |\n",
      "|    episodes         | 1000       |\n",
      "|    fps              | 409        |\n",
      "|    time_elapsed     | 35         |\n",
      "|    total_timesteps  | 14700      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.2      |\n",
      "|    ep_rew_mean      | 14.812388 |\n",
      "|    exploration_rate | 0.981     |\n",
      "| time/               |           |\n",
      "|    episodes         | 1100      |\n",
      "|    fps              | 411       |\n",
      "|    time_elapsed     | 39        |\n",
      "|    total_timesteps  | 16100     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.3      |\n",
      "|    ep_rew_mean      | 14.861217 |\n",
      "|    exploration_rate | 0.979     |\n",
      "| time/               |           |\n",
      "|    episodes         | 1200      |\n",
      "|    fps              | 413       |\n",
      "|    time_elapsed     | 42        |\n",
      "|    total_timesteps  | 17700     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 14.954269 |\n",
      "|    exploration_rate | 0.977     |\n",
      "| time/               |           |\n",
      "|    episodes         | 1300      |\n",
      "|    fps              | 417       |\n",
      "|    time_elapsed     | 45        |\n",
      "|    total_timesteps  | 19200     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.52756 |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 20600    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.2      |\n",
      "|    ep_rew_mean      | 14.479898 |\n",
      "|    exploration_rate | 0.974     |\n",
      "| time/               |           |\n",
      "|    episodes         | 1500      |\n",
      "|    fps              | 422       |\n",
      "|    time_elapsed     | 52        |\n",
      "|    total_timesteps  | 22000     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.3      |\n",
      "|    ep_rew_mean      | 14.647501 |\n",
      "|    exploration_rate | 0.972     |\n",
      "| time/               |           |\n",
      "|    episodes         | 1600      |\n",
      "|    fps              | 423       |\n",
      "|    time_elapsed     | 55        |\n",
      "|    total_timesteps  | 23500     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/            |            |\n",
      "|    ep_len_mean      | 14.3       |\n",
      "|    ep_rew_mean      | 14.6805315 |\n",
      "|    exploration_rate | 0.97       |\n",
      "| time/               |            |\n",
      "|    episodes         | 1700       |\n",
      "|    fps              | 425        |\n",
      "|    time_elapsed     | 58         |\n",
      "|    total_timesteps  | 24900      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 14.587774 |\n",
      "|    exploration_rate | 0.969     |\n",
      "| time/               |           |\n",
      "|    episodes         | 1800      |\n",
      "|    fps              | 426       |\n",
      "|    time_elapsed     | 62        |\n",
      "|    total_timesteps  | 26500     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 15.02019 |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 28000    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 14.775786 |\n",
      "|    exploration_rate | 0.965     |\n",
      "| time/               |           |\n",
      "|    episodes         | 2000      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 68        |\n",
      "|    total_timesteps  | 29300     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.6      |\n",
      "|    ep_rew_mean      | 14.682865 |\n",
      "|    exploration_rate | 0.964     |\n",
      "| time/               |           |\n",
      "|    episodes         | 2100      |\n",
      "|    fps              | 426       |\n",
      "|    time_elapsed     | 71        |\n",
      "|    total_timesteps  | 30700     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 15.36199 |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 32100    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.2      |\n",
      "|    ep_rew_mean      | 15.418416 |\n",
      "|    exploration_rate | 0.959     |\n",
      "| time/               |           |\n",
      "|    episodes         | 2400      |\n",
      "|    fps              | 426       |\n",
      "|    time_elapsed     | 81        |\n",
      "|    total_timesteps  | 34700     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.3      |\n",
      "|    ep_rew_mean      | 15.354221 |\n",
      "|    exploration_rate | 0.957     |\n",
      "| time/               |           |\n",
      "|    episodes         | 2500      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 84        |\n",
      "|    total_timesteps  | 36400     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 15.164012 |\n",
      "|    exploration_rate | 0.955     |\n",
      "| time/               |           |\n",
      "|    episodes         | 2600      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 87        |\n",
      "|    total_timesteps  | 37800     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 15.047252 |\n",
      "|    exploration_rate | 0.953     |\n",
      "| time/               |           |\n",
      "|    episodes         | 2700      |\n",
      "|    fps              | 430       |\n",
      "|    time_elapsed     | 91        |\n",
      "|    total_timesteps  | 39300     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/            |            |\n",
      "|    ep_len_mean      | 14.3       |\n",
      "|    ep_rew_mean      | 15.2197075 |\n",
      "|    exploration_rate | 0.952      |\n",
      "| time/               |            |\n",
      "|    episodes         | 2800       |\n",
      "|    fps              | 429        |\n",
      "|    time_elapsed     | 94         |\n",
      "|    total_timesteps  | 40600      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.1      |\n",
      "|    ep_rew_mean      | 14.848669 |\n",
      "|    exploration_rate | 0.95      |\n",
      "| time/               |           |\n",
      "|    episodes         | 2900      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 98        |\n",
      "|    total_timesteps  | 42200     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.77373 |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 43700    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.86718 |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 45400    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 14.190279 |\n",
      "|    exploration_rate | 0.944     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3200      |\n",
      "|    fps              | 431       |\n",
      "|    time_elapsed     | 108       |\n",
      "|    total_timesteps  | 46800     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.8      |\n",
      "|    ep_rew_mean      | 14.266844 |\n",
      "|    exploration_rate | 0.943     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3300      |\n",
      "|    fps              | 431       |\n",
      "|    time_elapsed     | 111       |\n",
      "|    total_timesteps  | 48300     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 14.089236 |\n",
      "|    exploration_rate | 0.941     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3400      |\n",
      "|    fps              | 432       |\n",
      "|    time_elapsed     | 114       |\n",
      "|    total_timesteps  | 49600     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 14.109596 |\n",
      "|    exploration_rate | 0.939     |\n",
      "| sess_time/          |           |\n",
      "|    ended_time       | 27.1      |\n",
      "|    session_minutes  | 46.7      |\n",
      "|    time_cutoff      | 22.8      |\n",
      "|    time_large       | 6.78      |\n",
      "|    time_medium      | 6.53      |\n",
      "|    time_small       | 6.83      |\n",
      "| size/               |           |\n",
      "|    ended_size       | 15.3      |\n",
      "|    inc_large        | 4.21      |\n",
      "|    inc_medium       | 4.09      |\n",
      "|    inc_small        | 4.17      |\n",
      "|    session_size     | 26        |\n",
      "|    size_cutoff      | 13.3      |\n",
      "| time/               |           |\n",
      "|    episodes         | 3500      |\n",
      "|    fps              | 421       |\n",
      "|    time_elapsed     | 121       |\n",
      "|    total_timesteps  | 51200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.507     |\n",
      "|    n_updates        | 2         |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.8      |\n",
      "|    ep_rew_mean      | 14.156849 |\n",
      "|    exploration_rate | 0.938     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3600      |\n",
      "|    fps              | 421       |\n",
      "|    time_elapsed     | 124       |\n",
      "|    total_timesteps  | 52600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.986     |\n",
      "|    n_updates        | 6         |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.6      |\n",
      "|    ep_rew_mean      | 13.969685 |\n",
      "|    exploration_rate | 0.936     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3700      |\n",
      "|    fps              | 422       |\n",
      "|    time_elapsed     | 128       |\n",
      "|    total_timesteps  | 54100     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.754     |\n",
      "|    n_updates        | 10        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.9      |\n",
      "|    ep_rew_mean      | 13.841221 |\n",
      "|    exploration_rate | 0.934     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3800      |\n",
      "|    fps              | 423       |\n",
      "|    time_elapsed     | 131       |\n",
      "|    total_timesteps  | 55600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.601     |\n",
      "|    n_updates        | 13        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.9      |\n",
      "|    ep_rew_mean      | 13.810545 |\n",
      "|    exploration_rate | 0.932     |\n",
      "| time/               |           |\n",
      "|    episodes         | 3900      |\n",
      "|    fps              | 423       |\n",
      "|    time_elapsed     | 134       |\n",
      "|    total_timesteps  | 57000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.2       |\n",
      "|    n_updates        | 17        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.9      |\n",
      "|    ep_rew_mean      | 13.610492 |\n",
      "|    exploration_rate | 0.931     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4000      |\n",
      "|    fps              | 424       |\n",
      "|    time_elapsed     | 137       |\n",
      "|    total_timesteps  | 58500     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.444     |\n",
      "|    n_updates        | 21        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 13.484565 |\n",
      "|    exploration_rate | 0.929     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4100      |\n",
      "|    fps              | 425       |\n",
      "|    time_elapsed     | 141       |\n",
      "|    total_timesteps  | 60000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.386     |\n",
      "|    n_updates        | 24        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 13.550271 |\n",
      "|    exploration_rate | 0.927     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4200      |\n",
      "|    fps              | 425       |\n",
      "|    time_elapsed     | 144       |\n",
      "|    total_timesteps  | 61400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.771     |\n",
      "|    n_updates        | 28        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 13.968387 |\n",
      "|    exploration_rate | 0.926     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4300      |\n",
      "|    fps              | 424       |\n",
      "|    time_elapsed     | 147       |\n",
      "|    total_timesteps  | 62700     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.769     |\n",
      "|    n_updates        | 31        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 14.205215 |\n",
      "|    exploration_rate | 0.924     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4400      |\n",
      "|    fps              | 425       |\n",
      "|    time_elapsed     | 150       |\n",
      "|    total_timesteps  | 64200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.31      |\n",
      "|    n_updates        | 35        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.6      |\n",
      "|    ep_rew_mean      | 14.301452 |\n",
      "|    exploration_rate | 0.922     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4500      |\n",
      "|    fps              | 425       |\n",
      "|    time_elapsed     | 154       |\n",
      "|    total_timesteps  | 65600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.429     |\n",
      "|    n_updates        | 38        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 14.543785 |\n",
      "|    exploration_rate | 0.92      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4600      |\n",
      "|    fps              | 426       |\n",
      "|    time_elapsed     | 157       |\n",
      "|    total_timesteps  | 67100     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.356     |\n",
      "|    n_updates        | 42        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.6      |\n",
      "|    ep_rew_mean      | 15.117155 |\n",
      "|    exploration_rate | 0.918     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4700      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 160       |\n",
      "|    total_timesteps  | 68700     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.552     |\n",
      "|    n_updates        | 46        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 15.165248 |\n",
      "|    exploration_rate | 0.917     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4800      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 164       |\n",
      "|    total_timesteps  | 70100     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.789     |\n",
      "|    n_updates        | 50        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.6      |\n",
      "|    ep_rew_mean      | 15.567428 |\n",
      "|    exploration_rate | 0.915     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4900      |\n",
      "|    fps              | 426       |\n",
      "|    time_elapsed     | 167       |\n",
      "|    total_timesteps  | 71400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.08      |\n",
      "|    n_updates        | 53        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 15.689898 |\n",
      "|    exploration_rate | 0.913     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5000      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 170       |\n",
      "|    total_timesteps  | 72900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.2       |\n",
      "|    n_updates        | 57        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 15.895787 |\n",
      "|    exploration_rate | 0.912     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5100      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 174       |\n",
      "|    total_timesteps  | 74500     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.15      |\n",
      "|    n_updates        | 61        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 16.163052 |\n",
      "|    exploration_rate | 0.91      |\n",
      "| time/               |           |\n",
      "|    episodes         | 5200      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 177       |\n",
      "|    total_timesteps  | 76000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.652     |\n",
      "|    n_updates        | 64        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 16.03388 |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5300     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 77500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.807    |\n",
      "|    n_updates        | 68       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 16.038094 |\n",
      "|    exploration_rate | 0.906     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5400      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 184       |\n",
      "|    total_timesteps  | 79000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.09      |\n",
      "|    n_updates        | 72        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.8      |\n",
      "|    ep_rew_mean      | 16.285181 |\n",
      "|    exploration_rate | 0.905     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5500      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 187       |\n",
      "|    total_timesteps  | 80300     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.964     |\n",
      "|    n_updates        | 75        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.9      |\n",
      "|    ep_rew_mean      | 16.000538 |\n",
      "|    exploration_rate | 0.903     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5600      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 191       |\n",
      "|    total_timesteps  | 82000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.905     |\n",
      "|    n_updates        | 79        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 16.00096 |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5700     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 83700    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.912    |\n",
      "|    n_updates        | 84       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 15.1      |\n",
      "|    ep_rew_mean      | 16.239248 |\n",
      "|    exploration_rate | 0.899     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5800      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 198       |\n",
      "|    total_timesteps  | 85100     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.713     |\n",
      "|    n_updates        | 87        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 15        |\n",
      "|    ep_rew_mean      | 15.974879 |\n",
      "|    exploration_rate | 0.897     |\n",
      "| time/               |           |\n",
      "|    episodes         | 5900      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 202       |\n",
      "|    total_timesteps  | 86500     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.995     |\n",
      "|    n_updates        | 91        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 15.1      |\n",
      "|    ep_rew_mean      | 15.848387 |\n",
      "|    exploration_rate | 0.896     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6000      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 205       |\n",
      "|    total_timesteps  | 87900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.883     |\n",
      "|    n_updates        | 94        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.9      |\n",
      "|    ep_rew_mean      | 15.495996 |\n",
      "|    exploration_rate | 0.894     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6100      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 208       |\n",
      "|    total_timesteps  | 89400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.891     |\n",
      "|    n_updates        | 98        |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.8      |\n",
      "|    ep_rew_mean      | 15.316542 |\n",
      "|    exploration_rate | 0.892     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6200      |\n",
      "|    fps              | 428       |\n",
      "|    time_elapsed     | 212       |\n",
      "|    total_timesteps  | 91000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.17      |\n",
      "|    n_updates        | 102       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 15        |\n",
      "|    ep_rew_mean      | 15.354278 |\n",
      "|    exploration_rate | 0.89      |\n",
      "| time/               |           |\n",
      "|    episodes         | 6300      |\n",
      "|    fps              | 427       |\n",
      "|    time_elapsed     | 215       |\n",
      "|    total_timesteps  | 92300     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.958     |\n",
      "|    n_updates        | 105       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.9      |\n",
      "|    ep_rew_mean      | 15.266896 |\n",
      "|    exploration_rate | 0.889     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6400      |\n",
      "|    fps              | 428       |\n",
      "|    time_elapsed     | 218       |\n",
      "|    total_timesteps  | 93700     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.18      |\n",
      "|    n_updates        | 109       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 14.961465 |\n",
      "|    exploration_rate | 0.887     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6500      |\n",
      "|    fps              | 428       |\n",
      "|    time_elapsed     | 221       |\n",
      "|    total_timesteps  | 95100     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.772     |\n",
      "|    n_updates        | 112       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 15.01077 |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6600     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 96500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.749    |\n",
      "|    n_updates        | 116      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 14.747316 |\n",
      "|    exploration_rate | 0.883     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6700      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 228       |\n",
      "|    total_timesteps  | 98200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.92      |\n",
      "|    n_updates        | 120       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 14.121167 |\n",
      "|    exploration_rate | 0.882     |\n",
      "| time/               |           |\n",
      "|    episodes         | 6800      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 231       |\n",
      "|    total_timesteps  | 99600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.14      |\n",
      "|    n_updates        | 123       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 14.389305 |\n",
      "|    exploration_rate | 0.88      |\n",
      "| sess_time/          |           |\n",
      "|    ended_time       | 27.4      |\n",
      "|    session_minutes  | 47.9      |\n",
      "|    time_cutoff      | 23.2      |\n",
      "|    time_large       | 6.29      |\n",
      "|    time_medium      | 6.67      |\n",
      "|    time_small       | 6.82      |\n",
      "| size/               |           |\n",
      "|    ended_size       | 15.7      |\n",
      "|    inc_large        | 3.97      |\n",
      "|    inc_medium       | 4.22      |\n",
      "|    inc_small        | 4.33      |\n",
      "|    session_size     | 26.7      |\n",
      "|    size_cutoff      | 13.6      |\n",
      "| time/               |           |\n",
      "|    episodes         | 6900      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 235       |\n",
      "|    total_timesteps  | 101000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.2       |\n",
      "|    n_updates        | 127       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 14.610526 |\n",
      "|    exploration_rate | 0.878     |\n",
      "| time/               |           |\n",
      "|    episodes         | 7000      |\n",
      "|    fps              | 428       |\n",
      "|    time_elapsed     | 238       |\n",
      "|    total_timesteps  | 102400    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.3       |\n",
      "|    n_updates        | 130       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 15.123943 |\n",
      "|    exploration_rate | 0.877     |\n",
      "| time/               |           |\n",
      "|    episodes         | 7100      |\n",
      "|    fps              | 428       |\n",
      "|    time_elapsed     | 242       |\n",
      "|    total_timesteps  | 103800    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.08      |\n",
      "|    n_updates        | 134       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.4      |\n",
      "|    ep_rew_mean      | 15.021287 |\n",
      "|    exploration_rate | 0.875     |\n",
      "| time/               |           |\n",
      "|    episodes         | 7200      |\n",
      "|    fps              | 428       |\n",
      "|    time_elapsed     | 245       |\n",
      "|    total_timesteps  | 105300    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.78      |\n",
      "|    n_updates        | 138       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.3      |\n",
      "|    ep_rew_mean      | 15.160038 |\n",
      "|    exploration_rate | 0.873     |\n",
      "| time/               |           |\n",
      "|    episodes         | 7300      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 248       |\n",
      "|    total_timesteps  | 106800    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.08      |\n",
      "|    n_updates        | 141       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.5      |\n",
      "|    ep_rew_mean      | 15.415256 |\n",
      "|    exploration_rate | 0.872     |\n",
      "| time/               |           |\n",
      "|    episodes         | 7400      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 251       |\n",
      "|    total_timesteps  | 108200    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.36      |\n",
      "|    n_updates        | 145       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 14.7      |\n",
      "|    ep_rew_mean      | 15.928825 |\n",
      "|    exploration_rate | 0.87      |\n",
      "| time/               |           |\n",
      "|    episodes         | 7500      |\n",
      "|    fps              | 429       |\n",
      "|    time_elapsed     | 255       |\n",
      "|    total_timesteps  | 109600    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.05      |\n",
      "|    n_updates        | 148       |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 16.02683 |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7600     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 111000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.98     |\n",
      "|    n_updates        | 152      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main(Argument)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
