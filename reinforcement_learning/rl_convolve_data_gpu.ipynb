{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install --upgrade awscli python-dotenv pqdm --quiet\n",
    "%load_ext dotenv\n",
    "%dotenv env\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_14.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_14.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_16.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_16.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_15.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_15.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_23.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_23.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_21.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_21.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_20.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_20.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_11.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_11.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_19.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_19.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_28.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_28.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_25.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_25.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_17.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_17.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_10.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_10.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_13.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_13.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_29.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_29.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_30.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_30.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_27.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_27.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_32.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_32.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_37.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_37.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_24.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_24.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_39.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_39.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_34.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_34.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_36.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_36.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_26.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_26.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_31.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_31.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_40.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_40.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_44.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_44.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_38.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_38.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_42.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_42.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_45.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_45.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_46.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_46.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_12.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_12.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_48.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_48.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_41.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_41.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_49.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_49.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_47.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_47.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_33.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_33.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_50.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_50.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_53.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_53.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_22.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_22.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_51.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_51.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_54.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_54.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_52.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_52.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_55.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_55.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_43.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_43.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_56.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_56.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_35.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_35.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_59.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_59.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_58.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_58.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_64.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_64.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_60.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_60.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_57.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_57.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_66.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_66.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_65.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_65.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_67.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_67.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_62.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_62.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_72.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_72.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_69.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_69.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_73.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_73.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_75.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_75.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_74.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_74.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_68.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_68.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_63.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_63.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_70.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_70.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_77.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_77.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_76.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_76.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_78.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_78.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_83.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_83.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_81.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_81.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_80.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_80.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_79.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_79.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_84.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_84.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_85.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_85.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_86.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_86.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_87.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_87.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_71.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_71.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_89.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_89.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_88.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_88.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_92.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_92.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_91.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_91.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_90.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_90.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_61.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_61.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_93.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_93.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_94.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_94.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_98.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_98.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_97.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_97.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_96.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_96.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_82.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_82.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_95.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_95.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_99.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_99.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_18.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_18.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_10.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_10.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_14.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_14.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_12.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_12.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_1.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_1.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_16.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_16.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_19.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_19.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_11.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_11.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_17.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_17.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_15.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_15.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_20.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_20.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_22.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_22.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_21.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_21.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_2.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_2.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_25.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_25.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_26.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_26.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_28.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_28.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_18.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_18.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_23.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_23.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_13.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_13.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_27.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_27.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_29.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_29.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_31.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_31.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_3.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_3.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_32.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_32.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_34.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_34.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_35.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_35.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_37.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_37.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_39.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_39.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_33.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_33.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_4.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_4.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_30.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_30.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_24.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_24.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_41.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_41.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_40.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_40.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_43.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_43.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_44.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_44.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_46.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_46.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_45.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_45.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_48.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_48.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_42.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_42.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_36.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_36.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_49.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_49.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_5.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_5.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_50.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_50.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_51.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_51.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_52.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_52.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_56.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_56.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_38.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_38.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_57.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_57.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_58.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_58.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_47.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_47.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_53.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_53.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_59.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_59.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_60.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_60.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_55.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_55.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_62.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_62.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_63.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_63.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_68.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_68.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_54.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_54.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_65.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_65.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_67.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_67.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_70.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_70.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_69.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_69.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_71.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_71.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_76.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_76.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_73.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_73.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_74.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_74.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_64.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_64.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_79.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_79.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_66.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_66.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_75.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_75.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_78.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_78.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_77.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_77.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_82.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_82.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_80.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_80.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_72.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_72.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_84.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_84.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_89.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_89.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_86.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_86.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_85.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_85.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_87.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_87.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_0.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_0.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_91.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_91.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_90.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_90.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_61.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_61.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_83.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_83.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_94.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_94.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_96.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_96.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_93.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_93.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_92.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_92.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_81.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_81.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_99.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_99.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_88.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_88.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_97.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_97.parquet\n",
      "^Cmpleted 715.0 MiB/720.5 MiB (45.7 MiB/s) with 2 file(s) remaining\n",
      "cancelled: ctrl-c received                                         \n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync rl_ready_data_conv s3://dissertation-data-dmiller/rl_ready_data_conv --delete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load rl_constant\n",
    "LABEL = [\n",
    "    \"continue_work_session_30_minutes\"\n",
    "]\n",
    "\n",
    "METADATA = [\n",
    "    \"user_id\",\n",
    "    \"session_30_raw\",\n",
    "    \"cum_platform_event_raw\",\n",
    "    \"cum_platform_time_raw\",\n",
    "    \"cum_session_time_raw\",\n",
    "    \"cum_session_event_raw\",\n",
    "    \"global_events_user\",\n",
    "    \"global_session_time\",\n",
    "    \"date_time\"\n",
    "]\n",
    "\n",
    "OUT_FEATURE_COLUMNS = [\n",
    "    \n",
    "    \"user_count\",\n",
    "    \"country_count\", \n",
    "    \"date_hour_sin\", \n",
    "    \"date_hour_cos\",\n",
    "    \"date_minute_sin\",\n",
    "    \"date_minute_cos\",\n",
    "    \n",
    "    \"session_30_count\",\n",
    "    \"session_5_count\",\n",
    "    \"cum_session_event\",\n",
    "    \"cum_session_time\",\n",
    "    \"expanding_click_average\",\n",
    "   \n",
    "    \"cum_platform_time\",\n",
    "    \"cum_platform_event\",\n",
    "    \"cum_projects\",\n",
    "    \"average_event_time\",\n",
    "    \"delta_last_event\",\n",
    "    \n",
    "    \"rolling_session_time\",\n",
    "    \"rolling_session_events\",\n",
    "    \"rolling_session_gap\",\n",
    "    \"previous_session_time\",\n",
    "    \"previous_session_events\",\n",
    "]\n",
    "\n",
    "RESCALER_COLS = [\n",
    "    'session_30_count',\n",
    "    'session_5_count',\n",
    "    'cum_session_event',\n",
    "    'cum_session_time',\n",
    "    'cum_platform_time',\n",
    "    'cum_platform_event',\n",
    "    'user_count',\n",
    "]\n",
    "\n",
    "PREDICTION_COLS = [\n",
    "    'pred',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "\n",
    "GROUPBY_COLS = ['user_id']\n",
    "\n",
    "RL_STAT_COLS = [\n",
    "    'session_size',\n",
    "    'sim_size',\n",
    "    'session_minutes',\n",
    "    'sim_minutes',\n",
    "    'reward',\n",
    "    'cum_session_time_raw'\n",
    "]\n",
    "\n",
    "TORCH_LOAD_COLS = [\n",
    "    'user_id',\n",
    "    'date_time'\n",
    "] + [\n",
    "    \"country_count\", \n",
    "    \"date_hour_sin\", \n",
    "    \"date_hour_cos\",\n",
    "    \"date_minute_sin\",\n",
    "    \"date_minute_cos\",\n",
    "    \"expanding_click_average\",\n",
    "    \"cum_projects\",\n",
    "    \"average_event_time\",\n",
    "    \"rolling_session_time\",\n",
    "    \"rolling_session_events\",\n",
    "    \"rolling_session_gap\",\n",
    "    \"previous_session_time\",\n",
    "    \"previous_session_events\",\n",
    "    \"delta_last_event\"\n",
    "] + [\n",
    "    'continue_work_session_30_minutes',\n",
    "    'session_30_raw',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint, pformat\n",
    "import cudf as gpu_pd\n",
    "\n",
    "logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "COLS_FOR_INFLECTION = [\n",
    "    'user_id',\n",
    "    'date_time',\n",
    "] + OUT_FEATURE_COLUMNS + PREDICTION_COLS\n",
    "\n",
    "class SessionCalculate:\n",
    "    logger = logging.getLogger('rl_results_eval')\n",
    "    def __init__(self, df, use_gpu) -> None:\n",
    "        self.df = df\n",
    "        self.use_gpu = use_gpu\n",
    "            \n",
    "        \n",
    "    def calculate_inflections(self):\n",
    "      \n",
    "        self.logger.info('Calculating subsequent date time')\n",
    "        self.df['next_date_time'] = self.df.groupby('user_id')['date_time'].shift(-1)\n",
    "        self.df = self.df.drop_duplicates(subset=['user_id', 'date_time'], keep='last').reset_index()\n",
    "        if self.use_gpu:\n",
    "            self.logger.info('Bringing to CPU for second calculation')\n",
    "            self.df = self.df.to_pandas()\n",
    "           \n",
    "            \n",
    "        self.df['diff_seconds'] = (self.df['next_date_time'] - self.df['date_time']).apply(lambda x: x.total_seconds())\n",
    "        \n",
    "        self.logger.info('Diff seconds calculated')\n",
    "        if self.use_gpu:\n",
    "            self.logger.info('Bringing back to GPU for final calculations')\n",
    "            self.df = cudf.from_pandas(self.df)\n",
    "\n",
    "        self.df['diff_minutes'] = (self.df['diff_seconds'] / 60)\n",
    "        self.df['session_5'] = (self.df['diff_minutes'] < 5)\n",
    "        self.df['session_30'] = self.df['diff_minutes'] < 30\n",
    "        \n",
    "        self.df['session_30'] = self.df['session_30'].fillna(False)\n",
    "        self.df['session_5'] = self.df['session_5'].fillna(False)        \n",
    "        self.logger.info(f'Labels calculated: removing rows with diff seconds > 0')\n",
    "       \n",
    "        \n",
    "\n",
    "        self.logger.info(f'Number of rows following drop: {self.df.shape[0]}')\n",
    "        self.logger.info(f'Sorting rows by date time and applying row count')\n",
    "        self.df = self.df.sort_values(['date_time']).reset_index()\n",
    "        self.df['row_count'] = self.df.index.values\n",
    "        self.logger.info(f'Sorted rows and applied row count on updated index')  \n",
    "        self.logger.info('Calculating inflection points')\n",
    "        self.df['user_id'] = self.df['user_id'].astype('int32')\n",
    "        \n",
    "       \n",
    "        inflections_5_merge = self.df[self.df['session_5'] == False].sort_values(by=['date_time'])\n",
    "        inflections_30_merge = self.df[self.df['session_30'] == False].sort_values(by=['date_time']) \n",
    "     \n",
    "        self.logger.info('Calculating session 5 inflections') \n",
    "        inflections_5_merge['session_5'] = inflections_5_merge.groupby('user_id').cumcount() + 1\n",
    "        inflections_5_merge = inflections_5_merge.rename(columns={'session_5': 'session_5_count'})\n",
    "        \n",
    "        self.logger.info('Calculating session 30 inflections')\n",
    "        inflections_30_merge['session_30'] = inflections_30_merge.groupby('user_id').cumcount() + 1\n",
    "        inflections_30_merge = inflections_30_merge.rename(columns={'session_30': 'session_30_count'})\n",
    "        \n",
    "        inflections_5_merge = inflections_5_merge[['user_id', 'date_time', 'row_count', 'session_5_count']].sort_values(by=['row_count', 'user_id'])\n",
    "        inflections_30_merge = inflections_30_merge[['user_id', 'date_time', 'row_count', 'session_30_count']].sort_values(by=['row_count', 'user_id'])\n",
    "        inflections_5_merge = inflections_5_merge.drop(columns=['date_time'])\n",
    "        \n",
    "        inflections_30_merge = inflections_30_merge.rename(columns={'date_time': 'session_end_time'})\n",
    "\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            self.logger.info('Bringing back to GPU for labelling')\n",
    "            self.df, inflections_5_merge, inflections_30_merge = self.df.to_pandas(), inflections_5_merge.to_pandas(), inflections_30_merge.to_pandas()\n",
    "            self.df = self.df.sort_values(by=['row_count', 'user_id'])\n",
    "            self.df = pd.merge_asof(self.df, inflections_5_merge, on='row_count', by='user_id', direction='forward')\n",
    "            self.df = pd.merge_asof(self.df, inflections_30_merge, on='row_count', by='user_id', direction='forward')\n",
    "            self.df['session_terminates_30_minutes'] = (self.df['session_end_time'] - self.df['date_time']).apply(lambda x: x.total_seconds() / 60) < 30\n",
    "            self.df = cudf.from_pandas(self.df)\n",
    "        else:\n",
    "            self.logger.info('Labelling on CPU')\n",
    "            self.df = pd.merge_asof(self.df.sort_values(by=['row_count', 'user_id']), inflections_5_merge, on='row_count', by='user_id', direction='forward')\n",
    "\n",
    "            self.df = pd.merge_asof(self.df.sort_values(by=['row_count', 'user_id']), inflections_5_merge, on='row_count', by='user_id', direction='forward')\n",
    "            self.df = pd.merge_asof(self.df.sort_values(by=['row_count', 'user_id']), inflections_30_merge, on='row_count', by='user_id', direction='forward') \n",
    "            self.df['session_terminates_30_minutes'] = (self.df['session_end_time'] - self.df['date_time']).apply(lambda x: x.total_seconds() / 60) < 30\n",
    " \n",
    "        self.logger.info('Inflections calculated')\n",
    " \n",
    "        session_end_30_minutes = self.df[self.df['session_terminates_30_minutes'] == False].shape[0]\n",
    "        self.logger.info(f'Percent sessions end in 30 minutes: {session_end_30_minutes / self.df.shape[0]}')\n",
    "        self.logger.info(f'Columns for df') \n",
    "        self.logger.info(pformat(self.df.columns))\n",
    "        \n",
    "        return self.df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "global logger\n",
    "logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('rl_results_eval')\n",
    "from functools import reduce\n",
    "from pprint import pformat\n",
    "import cudf as gpu_pd\n",
    "import cupy as gpu_np\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('mode.use_inf_as_na', True)\n",
    "from pqdm.processes import pqdm\n",
    "from cuml.preprocessing import MinMaxScaler\n",
    "\n",
    "def convolve_delta_events(df, window, write_path):\n",
    "    \n",
    "    df = df.to_pandas()\n",
    "   \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    before_resample = df.shape\n",
    "    logger.info(f'Convolutional shape before resample: {before_resample}')\n",
    "    logger.info(f'Convolution over delta last event')\n",
    "    \n",
    "    df['delta_last_event'] = (\n",
    "        df.sort_values(by=['session_30_raw', 'cum_session_event_raw']) \\\n",
    "            .set_index('date_time') \\\n",
    "            .groupby(by=['user_id', 'session_30_raw'], group_keys=False) \\\n",
    "            .rolling(f'{window}T', min_periods=1)['delta_last_event'] \\\n",
    "            .mean()\n",
    "            .reset_index(name='convolved_event_delta')['convolved_event_delta'] \\\n",
    "    ) \n",
    "\n",
    "    df = df.drop(columns=['session_30_raw'])\n",
    "    df = df.loc[:,~df.columns.duplicated()].reset_index(drop=True)  \n",
    "    \n",
    "\n",
    "    \n",
    "    df = gpu_pd.from_pandas(df)\n",
    "  \n",
    "    # remove duplicate columns\n",
    "    df['year'] = df['date_time'].dt.year\n",
    "    df['month'] = df['date_time'].dt.month\n",
    "    df['day'] = df['date_time'].dt.day\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    df['minute'] = df['date_time'].dt.minute\n",
    "    df['second'] = df['date_time'].dt.second\n",
    "    \n",
    "    df['user_id'] = df['user_id'].astype('int32')\n",
    "    \n",
    "   \n",
    "    resampled_df = df.sort_values(by='date_time') \\\n",
    "        .drop_duplicates(subset=['user_id', 'year', 'month', 'day', 'hour', 'minute'], keep='last') \\\n",
    "        .sort_values(by=['date_time']) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    logger.info(f'Convolution complete: {before_resample} -> {resampled_df.shape}')\n",
    "    logger.info(f'Writing intermediate results to {write_path}_convolve.parquet')\n",
    "    \n",
    "    resampled_df.to_parquet(os.path.join(write_path, 'convolve.parquet'))\n",
    "    \n",
    "    logger.info(f'Recalculating inflections')\n",
    "    resample_events = SessionCalculate(resampled_df, use_gpu=True)\n",
    "    resampled_event_out = resample_events.calculate_inflections()\n",
    "   \n",
    "    logger.info(f'Events sessionized: writing to {write_path}_session.parquet')\n",
    "    \n",
    "    resampled_event_out.to_parquet(os.path.join(write_path, 'session.parquet'))\n",
    "    logger.info(f'Events resampled')\n",
    "    \n",
    "    return resampled_event_out\n",
    "     \n",
    "     \n",
    "\n",
    "def generate_metadata_session(dataset):\n",
    "    \n",
    "    logger.info(f'Calculating session size and minutes')\n",
    "    session_size = dataset.groupby(['user_id', 'session_30_count'])['cum_session_event'].max().reset_index(name='session_size')\n",
    "    session_minutes = dataset.groupby(['user_id', 'session_30_count'])['cum_session_time'].max().reset_index(name='session_minutes')\n",
    "    \n",
    "    \n",
    "    logger.info(f'Calculating sim size and minutes')\n",
    "    sim_minutes = dataset.groupby(['user_id', 'session_30_count'])['cum_session_time'].quantile(.5, interpolation='nearest').reset_index(name='time_cutoff')\n",
    "    sim_size = dataset.groupby(['user_id', 'session_30_count'])['cum_session_event'].quantile(.5, interpolation='nearest').reset_index(name='size_cutoff')\n",
    "    \n",
    "    \n",
    "    sessions = [session_size, session_minutes, sim_minutes, sim_size]\n",
    "    logger.info(f'Merging metadata')\n",
    "    sessions = reduce(lambda left, right: pd.merge(left, right, on=['user_id', 'session_30_count']), sessions)\n",
    "   \n",
    "    logger.info(f'Merging metadata complete')\n",
    "    dataset = pd.merge(dataset, sessions, on=['user_id', 'session_30_count'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "def setup_data_at_window(df, window, write_path):\n",
    "    logger.info(f'Convolution over {window} minute window')\n",
    "    df = df.sort_values(by='date_time')\n",
    "    df['cum_session_event_raw'] = df.groupby(['user_id', 'session_30_raw'])['date_time'].cumcount() + 1\n",
    "    df = df.sort_values(by='date_time').reset_index(drop=True)\n",
    "    df  = convolve_delta_events(df, window, write_path)\n",
    "    logger.info(f'Convolving over {window} minute window complete: generating metadata')\n",
    "    logger.info(f'Generating metadata complete')\n",
    "    return df\n",
    "\n",
    "def partition_and_scale_data(df):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_split, eval_split = df[:int(df.shape[0] * .7)], df[int(df.shape[0] * .7):]\n",
    "    train_split[RESCALER_COLS] = scaler.fit_transform(train_split[RESCALER_COLS])\n",
    "    eval_split[RESCALER_COLS] = scaler.transform(eval_split[RESCALER_COLS])\n",
    "    return train_split, eval_split\n",
    "\n",
    "\n",
    "def _parralel_partition_users(unique_sessions, df, index, vec_df_path):\n",
    "    subset_session = df.merge(unique_sessions, on=['user_id', 'session_30_count_raw'], how='inner').reset_index(drop=True)\n",
    "    subset_session.to_parquet(f'{vec_df_path}/batch_{index}.parquet')\n",
    "    \n",
    "\n",
    "def reassign_value_counts(df):\n",
    "    user_count = df.groupby(['user_id']).size().reset_index(name='user_count')\n",
    "    \n",
    "    df = df.merge(user_count, on=['user_id'], how='inner')\n",
    "    return df\n",
    "\n",
    "def batch_environments_for_vectorization(df, n_envs, vec_df_path):\n",
    "   \n",
    "    df[['user_id', 'session_30_count_raw']] = df[['user_id', 'session_30_count_raw']].astype(int)\n",
    "   \n",
    "    unique_sessions = df[['user_id', 'session_30_count_raw']].drop_duplicates().sample(frac=1).reset_index(drop=True)\n",
    "    logger.info(f'Unique sessions shape: {unique_sessions.shape}. Splitting into {n_envs} environments')\n",
    "    unique_session_split = np.array_split(unique_sessions, n_envs)\n",
    "    \n",
    "    unique_session_args = [{\n",
    "        'unique_sessions': sess,\n",
    "        'df': df,\n",
    "        'index': i,\n",
    "        'vec_df_path': vec_df_path,\n",
    "    } for i, sess in enumerate(unique_session_split)]\n",
    "\n",
    "    logger.info(f'Environments split: running parralel partitioning')\n",
    "    result = pqdm(unique_session_args, _parralel_partition_users, n_jobs=os.cpu_count() * 2, argument_type='kwargs')\n",
    "    logger.info(f'Environments split: finished parralel partitioning')\n",
    "    return result\n",
    "\n",
    "\n",
    "def reset_intra_session(df):\n",
    "   \n",
    "    logger.info(f'Dropping sessions with less than one event') \n",
    "    \n",
    "    \n",
    "    \n",
    "    logger.info(f'Resetting cum_session_event_count')\n",
    "    df['cum_session_event'] = df.groupby(['user_id', 'session_30_count'])['date_time'].cumcount() + 1\n",
    "    logger.info(f'Resetting cum_session_time and setting reward')\n",
    "    df = df.to_pandas()\n",
    "    df['reward'] = df.groupby(['user_id', 'session_30_count'])['date_time'].diff().dt.total_seconds().fillna(0) / 60\n",
    "    df['reward'] = df[['reward', 'cum_session_event']].apply(lambda x: x['reward'] if x['cum_session_event'] > 1 else 0, axis=1)\n",
    "    df['cum_session_time'] = df.groupby(['user_id', 'session_30_count'])['reward'].cumsum()\n",
    "    \n",
    "    logger.info(f'Resetting cum_platform_time and cum_platform_events')\n",
    "    df['cum_platform_time'] = df.groupby(['user_id'])['reward'].cumsum()\n",
    "    df['cum_platform_event'] = df.groupby(['user_id'])['cum_session_event'].cumcount()\n",
    "    \n",
    "    df = gpu_pd.from_pandas(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_dataset(read_path, conv_path, n_files, window, n_envs):\n",
    "    \n",
    "    conv_path, read_path = (\n",
    "        os.path.join(conv_path, f'files_used_{n_files}'),\n",
    "        os.path.join(read_path, f'files_used_{n_files}', 'predicted_data.parquet')\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(conv_path):\n",
    "        logger.info(f'Creating directory {conv_path}')\n",
    "        os.makedirs(conv_path)\n",
    "    \n",
    "    logger.info(f'Convolutional dataset not found at {conv_path}: creating')\n",
    "    logger.info(f'Getting dataset from {read_path}')\n",
    "    columns = TORCH_LOAD_COLS + ['seq_20' if n_files == 2 else 'seq_40']\n",
    "    df = gpu_pd.read_parquet(read_path, columns=columns)\n",
    "    \n",
    "    df['date_time'] = gpu_pd.to_datetime(df['date_time'])\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        'continue_work_session_30_minutes' if 'continue_work_session_30_minutes' in df.columns else \\\n",
    "            'session_terminates_30_minutes': 'label',\n",
    "        'seq_40' if 'seq_40' in df.columns else 'seq_20': 'pred'\n",
    "    })\n",
    "    \n",
    "\n",
    "    logger.info(f'Non nan values: {df.count().min()}: 3ropping na')\n",
    "    logger.info(f'NA values dropped: {df.count().min()}')\n",
    "    \n",
    "    df = df.sort_values(by='date_time')\n",
    "\n",
    "   \n",
    "    logger.info(f'Initial shape: {df.shape}: dropping na and inf')\n",
    "    df = df.dropna()\n",
    "    logger.info(f'Final shape: {df.shape}: dropping na and inf')\n",
    "    \n",
    "    logger.info(f'Reassgning user counts')\n",
    "    df = reassign_value_counts(df)\n",
    "    logger.info(f'User counts reassigned')\n",
    "    \n",
    "        \n",
    "    base_conv_path = os.path.join(conv_path, f'window_{window}')\n",
    "    # intermediate_conv_path = os.path.join(base_conv_path, 'intermediate')\n",
    "    # if not os.path.exists(base_conv_path):\n",
    "    #     logger.info(f'Creating directory {base_conv_path}')\n",
    "    #     os.makedirs(base_conv_path)\n",
    "    \n",
    "    # if not os.path.exists(intermediate_conv_path):\n",
    "    #     logger.info(f'Creating directory {intermediate_conv_path}')\n",
    "    #     os.makedirs(intermediate_conv_path)\n",
    "        \n",
    "    # df = df.sort_values(by='date_time')\n",
    "    # logger.info(f'Subset setup complete: {df.shape}')\n",
    "    # df = setup_data_at_window(df, window, intermediate_conv_path)\n",
    "    # logger.info(f'Subset convolution complete: {df.shape}, resetting stats')\n",
    "    # df = df.sort_values(by='date_time')\n",
    "    # df = reset_intra_session(df)    \n",
    "    # logger.info(f'Intra session stats calculated: {df.shape}, saving intermediate')\n",
    "    # df.to_parquet(os.path.join(intermediate_conv_path, 'intra_session.parquet'))\n",
    "    # logger.info(f'Intra session reset complete: {df.shape}')\n",
    "    # logger.info(f'Stats reset complete, resetting metadata')\n",
    "    # df = df.to_pandas()\n",
    "    # df = generate_metadata_session(df)\n",
    "    # logger.info(f'Metadata reset complete: {df.shape}')\n",
    "        \n",
    "    # is_monotic_increasing_sess_time = df.round(3).groupby(['user_id', 'session_30_count'])['cum_session_time'].is_monotonic_increasing.reset_index(name='is_monotic_increasing')\n",
    "        \n",
    "    # if is_monotic_increasing_sess_time[is_monotic_increasing_sess_time['is_monotic_increasing'] == False].shape[0] > 0:\n",
    "    #     logger.info(f'Non monotonic increasing reward found: perc {is_monotic_increasing_sess_time[is_monotic_increasing_sess_time[\"is_monotic_increasing\"] == False].shape[0] / is_monotic_increasing_sess_time.shape[0]}')\n",
    "    #     logger.info(is_monotic_increasing_sess_time[is_monotic_increasing_sess_time[\"is_monotic_increasing\"] == False])\n",
    "    # else:\n",
    "    #     logger.info(f'All rewards are monotonic increasing and no errors')\n",
    "            \n",
    "        \n",
    "    # is_monotic_increasing_date_time = df.round(3).groupby(['user_id'])['date_time'].is_monotonic_increasing.reset_index(name='is_monotic_increasing')\n",
    "        \n",
    "    # if is_monotic_increasing_date_time[is_monotic_increasing_date_time['is_monotic_increasing'] == False].shape[0] > 0:\n",
    "    #     logger.info(f'Non monotonic increasing date time found: perc {is_monotic_increasing_date_time[is_monotic_increasing_date_time[\"is_monotic_increasing\"] == False].shape[0] / is_monotic_increasing_date_time.shape[0]}')\n",
    "    #     logger.info(is_monotic_increasing_date_time[is_monotic_increasing_date_time[\"is_monotic_increasing\"] == False])\n",
    "    # else:\n",
    "    #     logger.info(f'All date times are monotonic increasing and no errors')\n",
    "        \n",
    "    # logger.info(f'Rescaling feature cols: {RESCALER_COLS}')\n",
    "    # for col in RESCALER_COLS:\n",
    "    #     df[f'{col}_raw'] = df[col] \n",
    "    # train_split, eval_split =  partition_and_scale_data(df)\n",
    "    \n",
    "    train_path, eval_path = (os.path.join(base_conv_path, 'train.parquet'), os.path.join(base_conv_path, 'eval.parquet'))\n",
    "    train_split, eval_split = pd.read_parquet(train_path), pd.read_parquet(eval_path)\n",
    "    # logger.info(f'Saving train splits o {train_path}')\n",
    "    # train_split.to_parquet(train_path)\n",
    "    # logger.info(f'Saving eval splits to {eval_path}')\n",
    "    # eval_split.to_parquet(eval_path)\n",
    "    logger.info(f'Saving train and eval splits to complete: setting batches {n_envs}')\n",
    "    batched_train_path, batched_eval_path = (os.path.join(base_conv_path, 'batched_train'), os.path.join(base_conv_path, 'batched_eval'))\n",
    "    \n",
    "    if not os.path.exists(batched_train_path):\n",
    "        logger.info(f'Creating directory {batched_train_path}')\n",
    "        os.makedirs(batched_train_path)\n",
    "    \n",
    "    if not os.path.exists(batched_eval_path):\n",
    "        logger.info(f'Creating directory {batched_eval_path}')\n",
    "        os.makedirs(batched_eval_path)\n",
    "    logger.info(f'Writing training batches to {batched_train_path}')\n",
    "    batch_environments_for_vectorization(train_split, n_envs, batched_train_path)\n",
    "    logger.info(f'Writing eval batches to {batched_eval_path}')\n",
    "    batch_environments_for_vectorization(eval_split, n_envs, batched_eval_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    read_path = 'rl_ready_data'\n",
    "    conv_path = 'rl_ready_data_conv'\n",
    "    n_files = 30\n",
    "    window = 1\n",
    "    n_envs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 10:38:59,456 - rl_results_eval - INFO - Convolutional dataset not found at rl_ready_data_conv/files_used_30: creating\n",
      "2023-06-12 10:38:59,458 - rl_results_eval - INFO - Getting dataset from rl_ready_data/files_used_30/predicted_data.parquet\n",
      "2023-06-12 10:39:02,884 - rl_results_eval - INFO - Non nan values: 36241442: 3ropping na\n",
      "2023-06-12 10:39:02,887 - rl_results_eval - INFO - NA values dropped: 36241442\n",
      "2023-06-12 10:39:03,016 - rl_results_eval - INFO - Initial shape: (36241442, 19): dropping na and inf\n",
      "2023-06-12 10:39:03,120 - rl_results_eval - INFO - Final shape: (36241442, 19): dropping na and inf\n",
      "2023-06-12 10:39:03,120 - rl_results_eval - INFO - Reassgning user counts\n",
      "2023-06-12 10:39:03,227 - rl_results_eval - INFO - User counts reassigned\n",
      "2023-06-12 10:39:04,560 - rl_results_eval - INFO - Saving train and eval splits to complete: setting batches 50\n",
      "2023-06-12 10:39:04,561 - rl_results_eval - INFO - Writing training batches to rl_ready_data_conv/files_used_30/window_1/batched_train\n",
      "2023-06-12 10:39:05,333 - rl_results_eval - INFO - Unique sessions shape: (383419, 2). Splitting into 50 environments\n",
      "2023-06-12 10:39:05,339 - rl_results_eval - INFO - Environments split: running parralel partitioning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e709d8c71b4c60bffcc5734030c3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8052976ab75842529bf31a3e0a11686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc48ed2a6d144087bffa76a3f19a7386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 10:43:39,964 - rl_results_eval - INFO - Environments split: finished parralel partitioning\n",
      "2023-06-12 10:43:39,966 - rl_results_eval - INFO - Writing eval batches to rl_ready_data_conv/files_used_30/window_1/batched_eval\n",
      "2023-06-12 10:43:40,305 - rl_results_eval - INFO - Unique sessions shape: (149561, 2). Splitting into 50 environments\n",
      "2023-06-12 10:43:40,309 - rl_results_eval - INFO - Environments split: running parralel partitioning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1192d4f89f54173b4faece5a39cbb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ade9194aa484400bae98872d8497fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c777156967974f3db6c056c8d1e3413d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 10:45:39,300 - rl_results_eval - INFO - Environments split: finished parralel partitioning\n"
     ]
    }
   ],
   "source": [
    "get_dataset(Arguments.read_path, Arguments.conv_path, Arguments.n_files, Arguments.window, Arguments.n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_0.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_0.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_18.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_18.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_16.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_16.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_19.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_19.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_20.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_20.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_2.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_2.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_21.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_21.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_22.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_22.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_23.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_23.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_25.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_25.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_26.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_26.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_24.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_24.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_27.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_27.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_1.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_1.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_13.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_13.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_29.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_29.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_15.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_15.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_3.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_3.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_33.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_33.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_32.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_32.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_10.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_10.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_34.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_34.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_30.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_30.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_35.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_35.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_37.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_37.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_38.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_38.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_43.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_43.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_31.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_31.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_42.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_42.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_28.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_28.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_45.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_45.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_4.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_4.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_44.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_44.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_12.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_12.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_49.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_49.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_5.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_5.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_46.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_46.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_47.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_47.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_41.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_41.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_8.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_8.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_14.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_14.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_7.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_7.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_6.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_6.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_9.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_9.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_1.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_1.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_40.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_40.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_36.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_36.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_39.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_39.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_17.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_17.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_11.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_11.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_48.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_eval/batch_48.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_11.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_11.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_10.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_10.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_0.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_0.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_12.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_12.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_17.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_17.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_18.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_18.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_13.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_13.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_2.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_2.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_20.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_20.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_14.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_14.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_19.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_19.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_15.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_15.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_16.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_16.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_21.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_21.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_23.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_23.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_22.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_22.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_27.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_27.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_25.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_25.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_24.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_24.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_26.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_26.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_28.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_28.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_30.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_30.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_29.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_29.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_3.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_3.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_35.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_35.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_31.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_31.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_32.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_32.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_33.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_33.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_34.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_34.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_4.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_4.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_36.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_36.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_37.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_37.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_39.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_39.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_41.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_41.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_38.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_38.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_40.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_40.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_42.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_42.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_43.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_43.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_44.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_44.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_49.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_49.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_46.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_46.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_45.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_45.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_5.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_5.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_6.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_6.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_47.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_47.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_95.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_95.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_9.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_9.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_48.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_48.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_98.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_98.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_7.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_7.parquet\n",
      "upload: rl_ready_data_conv/files_used_30/window_1/batched_train/batch_8.parquet to s3://dissertation-data-dmiller/rl_ready_data_conv/files_used_30/window_1/batched_train/batch_8.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync rl_ready_data_conv s3://dissertation-data-dmiller/rl_ready_data_conv --delete"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
