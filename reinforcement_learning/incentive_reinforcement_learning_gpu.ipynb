{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install python-dotenv --quiet\n",
    "!python -m pip install gym stable-baselines3[extra] --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load rl_constant.py\n",
    "LABEL = [\n",
    "    \"continue_work_session_30_minutes\"\n",
    "]\n",
    "\n",
    "METADATA = [\n",
    "    \"user_id\",\n",
    "    \"session_30_raw\",\n",
    "    \"cum_platform_event_raw\",\n",
    "    \"cum_platform_time_raw\",\n",
    "    \"cum_session_time_raw\",\n",
    "    \"cum_session_event_raw\",\n",
    "    \"global_events_user\",\n",
    "    \"global_session_time\",\n",
    "    \"date_time\",\n",
    "]\n",
    "\n",
    "OUT_FEATURE_COLUMNS = [\n",
    "    \"country_count\", \n",
    "    \"date_hour_sin\", \n",
    "    \"date_hour_cos\",\n",
    "    \"date_minute_sin\",\n",
    "    \"date_minute_cos\",\n",
    "    \n",
    "    \"session_30_count\",\n",
    "    \"session_5_count\",\n",
    "    \"cum_session_event_count\",\n",
    "    \"delta_last_event\",\n",
    "    \"cum_session_time\",\n",
    "    \n",
    "    \"expanding_click_average\",\n",
    "    \"cum_platform_time\",\n",
    "    \"cum_platform_events\",\n",
    "    \"cum_projects\",\n",
    "    \"average_event_time\",\n",
    "    \n",
    "    \"rolling_session_time\",\n",
    "    \"rolling_session_events\",\n",
    "    \"rolling_session_gap\",\n",
    "    \"previous_session_time\",\n",
    "    \"previous_session_events\",\n",
    "]\n",
    "\n",
    "PREDICTION_COLS = [\n",
    "    'seq_40',\n",
    "]\n",
    "\n",
    "\n",
    "GROUPBY_COLS = ['user_id']\n",
    "\n",
    "RL_STAT_COLS = [\n",
    "    'session_size',\n",
    "    'sim_size',\n",
    "    'session_minutes',\n",
    "    'sim_minutes',\n",
    "    'reward',\n",
    "]\n",
    "\n",
    "TORCH_LOAD_COLS = list(set(LABEL + METADATA + OUT_FEATURE_COLUMNS + RL_STAT_COLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load environment\n",
    "import gym\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm \n",
    "import gym\n",
    "from datetime import datetime\n",
    "\n",
    "class CitizenScienceEnv(gym.Env):\n",
    "    \n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, dataset, out_features, n_sequences, evaluation=False):\n",
    "        \"\"\"\n",
    "        trajectories: dictionary of user_id to their respective trajectories.\n",
    "        n_sequences: number of sequences used for preprocessing.\n",
    "        n_features: number of features used for preprocessing.\n",
    "        \"\"\"\n",
    "        super(CitizenScienceEnv, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.n_sequences = n_sequences\n",
    "        self.current_session = None\n",
    "        self.current_session_index = 0\n",
    "        self.reward = 0\n",
    "        self.n_sequences = n_sequences\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(low=-1, high=1, shape=(len(out_features), n_sequences + 1), dtype=np.float32)\n",
    "        self.evalution = evaluation\n",
    "        self.episode_bins = []\n",
    "\n",
    "    def reset(self):\n",
    "        user_to_run, session_to_run = self.dataset.sample(1)[['user_id', 'session_30_raw']].values[0]\n",
    "        self.current_session = self._get_events(user_to_run, session_to_run)\n",
    "        self.metadata = self._metadata()\n",
    "        self.current_session_index = 0\n",
    "        self.reward = 0\n",
    "        return self._state()\n",
    "    \n",
    "    def _row_to_dict(self, metadata):\n",
    "        \"\"\"\n",
    "        Convert a row of metadata to a dictionary.\n",
    "        \"\"\"\n",
    "        return metadata.to_dict()\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        self._take_action(action)\n",
    "        next_state, done, meta = self._calculate_next_state()\n",
    "        \n",
    "        if done:\n",
    "            current_session_index = self.current_session_index if \\\n",
    "                self.current_session_index != self.current_session.shape[0] else self.current_session.shape[0] - 1\n",
    "        \n",
    "            self.metadata['ended'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "            self.metadata['reward'] = self.current_session.iloc[current_session_index]['reward']\n",
    "            if self.evalution:\n",
    "                self.episode_bins.append(self._row_to_dict(self.metadata))\n",
    "            return next_state, float(self.reward), done, {}\n",
    "        else:\n",
    "            self.reward = self.current_session.iloc[self.current_session_index]['reward'] \n",
    "            self.current_session_index += 1        \n",
    "            return next_state, float(self.reward), done, meta\n",
    "    \n",
    "    def _metadata(self):\n",
    "        session_metadata = self.current_session.iloc[0][RL_STAT_COLS]\n",
    "        session_metadata['ended'] = 0\n",
    "        session_metadata['incentive_index'] = 0\n",
    "        return session_metadata\n",
    "    \n",
    "    \n",
    "    def _calculate_next_state(self):\n",
    "        \n",
    "        if (self.current_session_index == self.current_session.shape[0]):\n",
    "            return None, True, {}\n",
    "\n",
    "        if self._continuing_in_session():\n",
    "            return self._state(), False, {}\n",
    "    \n",
    "        return None, True, {}\n",
    "        \n",
    "      \n",
    "  \n",
    "    def _continuing_in_session(self):\n",
    "        sim_counts = self.metadata['sim_size']\n",
    "        current_session_count = self.current_session.iloc[self.current_session_index]['cum_session_event_raw']\n",
    "        if current_session_count < sim_counts:\n",
    "            return True\n",
    "        \n",
    "        extending_session = self._probability_extending_session(current_session_count)\n",
    "        \n",
    "        return all([extending_session >= .3, extending_session <= .7])\n",
    "        \n",
    "    \n",
    "    def _probability_extending_session(self, current_session_count):\n",
    "        if self.metadata['incentive_index'] == 0:\n",
    "            return 0\n",
    "        \n",
    "        scale = max(5, int(self.metadata['session_size'] / 4))\n",
    "        continue_session = norm(\n",
    "            loc=self.metadata['incentive_index'],\n",
    "            scale=scale\n",
    "        ).cdf(current_session_count)\n",
    "        \n",
    "        return continue_session\n",
    "        \n",
    "\n",
    "    def _get_events(self, user_id, session):\n",
    "        subset = self.dataset[\n",
    "            (self.dataset['user_id'] == user_id) &\n",
    "            (self.dataset['session_30_raw'] == session)\n",
    "        ]\n",
    "        \n",
    "        subset = subset.sort_values(by=['session_30_raw', 'cum_session_event_raw'])\n",
    "       \n",
    "        print(subset[['date_time', 'cum_session_event_raw', 'cum_session_time_raw', 'reward']]) \n",
    "        assert subset['cum_session_event_raw'].is_monotonic_increasing\n",
    "        assert subset['cum_session_time_raw'].is_monotonic_increasing\n",
    "        assert subset['reward'].is_monotonic_increasing\n",
    "        return subset\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "        if action == 0 or self.metadata['incentive_index'] > 0:\n",
    "            return\n",
    "        \n",
    "        current_session_index = self.current_session_index if \\\n",
    "            self.current_session_index != self.current_session.shape[0] else self.current_session.shape[0] - 1\n",
    "        \n",
    "        self.metadata['incentive_index'] = self.current_session.iloc[current_session_index]['cum_session_event_raw']\n",
    "        self.metadata['incentive_time'] = self.current_session.iloc[current_session_index]['cum_session_time_raw']\n",
    "        \n",
    "    def _state(self):\n",
    "\n",
    "        if self.current_session_index > self.n_sequences:\n",
    "            events = self.current_session.iloc[self.current_session_index - (self.n_sequences + 1):self.current_session_index][self.out_features].values\n",
    "            \n",
    "        else:\n",
    "            delta = min((self.n_sequences + 1)- self.current_session_index, self.n_sequences)\n",
    "            zero_cat = np.zeros((delta, len(self.out_features)))\n",
    "            events = self.current_session.iloc[:max(self.current_session_index, 1)][self.out_features].values\n",
    "            events = np.concatenate((zero_cat, events), axis=0)\n",
    "            \n",
    "\n",
    "        return events.astype(np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load policies/cnn_policy\n",
    "# %load policies/cnn_policy\n",
    "from typing import Dict, List, Type, Union\n",
    "\n",
    "import gym\n",
    "import torch\n",
    "from gym import spaces\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.dqn.policies import DQNPolicy\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CustomConv1dFeatures(BaseFeaturesExtractor):\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_sequences_features(cls, n_sequences, n_features):\n",
    "        cls.n_sequences = n_sequences\n",
    "        cls.n_features = n_features\n",
    "        \n",
    "    \n",
    "    def __init__(self, observation_space: spaces.Box, features_dim=20):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        \n",
    "        \n",
    "        self.cnn_1 = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features*2),\n",
    "            nn.Conv1d(self.n_features*2, self.n_features*2, kernel_size=3, padding=1),\n",
    "            \n",
    "            nn.AvgPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.cnn_2 = nn.Sequential(\n",
    "            nn.Conv1d(self.n_features*2, self.n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(self.n_features, self.n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(self.n_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.act = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out_shape = self.act(self.cnn_2(self.cnn_1(torch.zeros((1, self.n_features, self.n_sequences))))).shape[1]\n",
    "            self.linear = nn.Linear(out_shape, features_dim)\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        out = self.cnn_1(obs)\n",
    "        out = self.cnn_2(out)\n",
    "        out = self.act(out)\n",
    "        return self.linear(out)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load incentive_reinforcement_learning_cpu.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from pprint import pformat\n",
    "from typing import Callable\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from stable_baselines3 import A2C, DQN, PPO\n",
    "from stable_baselines3.common.callbacks import (CallbackList,\n",
    "                                                CheckpointCallback,\n",
    "                                                StopTrainingOnMaxEpisodes)\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.dqn.policies import DQNPolicy\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)\n",
    "np.set_printoptions(precision=4, linewidth=200, suppress=True)\n",
    "torch.set_printoptions(precision=2, linewidth=200, sci_mode=False)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parse = argparse.ArgumentParser()\n",
    "    parse.add_argument('--read_path', type=str, default='rl_ready_data_conv')\n",
    "    parse.add_argument('--n_files', type=int, default=2)\n",
    "    parse.add_argument('--n_episodes', type=int, default=50)\n",
    "    parse.add_argument('--n_envs', type=int, default=100)\n",
    "    parse.add_argument('--lstm', type=str, default='seq_10')\n",
    "    parse.add_argument('--part', type=str, default='train')\n",
    "    parse.add_argument('--feature_extractor', type=str, default='cnn') \n",
    "    args = parse.parse_args()\n",
    "    return args\n",
    "\n",
    "def _lstm_loader(lstm):\n",
    "    \n",
    "    return LABEL[0] if lstm == 'label' else lstm\n",
    "\n",
    "def load_and_dedupe(read_path, cols):\n",
    "    df = pd.read_parquet(read_path, columns=cols)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "S3_BASELINE_PATH = 's3://dissertation-data-dmiller'\n",
    "N_SEQUENCES = 40\n",
    "CHECKPOINT_FREQ = 100_000\n",
    "TB_LOG = 10_000\n",
    "WINDOW = 2\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    exec_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    logger.info('Starting Incentive Reinforcement Learning')\n",
    "    logger.info(pformat(args.__dict__))\n",
    "    \n",
    "    read_path, n_files, n_episodes, n_envs, lstm, part, feature_ext = (\n",
    "        args.read_path, \n",
    "        args.n_files, \n",
    "        args.n_episodes, \n",
    "        args.n_envs,\n",
    "        args.lstm,\n",
    "        args.part,\n",
    "        args.feature_extractor,\n",
    "    )\n",
    "    \n",
    "    read_path = os.path.join(\n",
    "        'rl_ready_data_conv',\n",
    "        f'files_used_{n_files}',\n",
    "        f'window_{WINDOW}_{part}.parquet'\n",
    "    )\n",
    "    \n",
    "    if not os.path.exists(read_path):\n",
    "        raise ValueError(f'No data found at {read_path}')\n",
    "    \n",
    "    logger.info(f'Reading data from {read_path}')\n",
    "    load_cols, out_features = (TORCH_LOAD_COLS + [lstm] if lstm else TORCH_LOAD_COLS, OUT_FEATURE_COLUMNS + [lstm] if lstm else OUT_FEATURE_COLUMNS)\n",
    "\n",
    "    df = load_and_dedupe(read_path, load_cols)\n",
    "    \n",
    "    df = df.sort_values(by=['session_30_raw', 'cum_session_event_raw'])\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(read_path):\n",
    "        raise ValueError(f'No data found at {read_path}')\n",
    " \n",
    "    lstm = _lstm_loader(lstm)\n",
    "     \n",
    "    logger.info(f'Loaded data with shape {df.shape}')\n",
    "    logger.info(f'Setting up convolution over {WINDOW}T minutes')\n",
    " \n",
    "    citizen_science_vec =DummyVecEnv([lambda: CitizenScienceEnv(df, out_features, N_SEQUENCES) for i in range(n_envs)])\n",
    "    logger.info(f'Vectorized environments created')\n",
    "    \n",
    "    base_path = os.path.join(\n",
    "        S3_BASELINE_PATH,\n",
    "        'reinforcement_learning_incentives_3',\n",
    "        f'n_files_{n_files}',\n",
    "        feature_ext + '_' + 'label' if lstm.startswith('continue') else feature_ext + f'_{lstm}',\n",
    "        'results',\n",
    "        exec_time,\n",
    "    ) \n",
    "    \n",
    "    \n",
    "    tensorboard_dir, checkpoint_dir = (\n",
    "        os.path.join(base_path, 'training_metrics'),\n",
    "        os.path.join(base_path, 'checkpoints')\n",
    "    )\n",
    "\n",
    "    logger.info(f'Creating callbacks, monitors and loggerss')\n",
    "    callback_max_episodes = StopTrainingOnMaxEpisodes(max_episodes=n_episodes, verbose=1)\n",
    "    checkpoint_callback = CheckpointCallback(save_freq=CHECKPOINT_FREQ// (n_envs // 2), save_path=checkpoint_dir, name_prefix='rl_model')\n",
    "    callback_list = CallbackList([callback_max_episodes, checkpoint_callback])\n",
    "    monitor_train = VecMonitor(citizen_science_vec)\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    if feature_ext == 'cnn':\n",
    "        CustomConv1dFeatures.setup_sequences_features(N_SEQUENCES + 1,len(out_features))\n",
    "        logger.info('Using custom 1 dimensional CNN feature extractor')\n",
    "        policy_kwargs = dict(\n",
    "            features_extractor_class=CustomConv1dFeatures,\n",
    "            net_arch=[10]\n",
    "        )\n",
    "        model = DQN(policy='CnnPolicy', env=monitor_train, verbose=1, tensorboard_log=tensorboard_dir, policy_kwargs=policy_kwargs, device=device, stats_window_size=1000)\n",
    "    else:\n",
    "        logger.info('Using default MLP feature extractor')\n",
    "        model = DQN(policy='MlpPolicy', env=monitor_train, verbose=1, tensorboard_log=tensorboard_dir, device=device, stats_window_size=1000)\n",
    "    \n",
    "    logger.info(f'Model created: policy')\n",
    "    \n",
    "    logger.info(pformat(model.policy))\n",
    "        \n",
    "    logger.info(f'Beginning training') \n",
    "            \n",
    "    logger.info(pformat([\n",
    "        'n_episodes: {}'.format(n_episodes),\n",
    "        'read_path: {}'.format(read_path),\n",
    "        'n_files: {}'.format(n_files),\n",
    "        'n_sequences: {}'.format(N_SEQUENCES),\n",
    "        'n_envs: {}'.format(n_envs),\n",
    "        'total_timesteps: {}'.format(df.shape),\n",
    "        'device: {}'.format(device),\n",
    "        'tensorboard_dir: {}'.format(tensorboard_dir),\n",
    "        'checkpoint_dir: {}'.format(checkpoint_dir)\n",
    "    ]))\n",
    "    \n",
    "    model.learn(total_timesteps=25_000_000, progress_bar=True, log_interval=TB_LOG, callback=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Argument:\n",
    "    read_path = 'rl_ready_data'\n",
    "    n_files = 30\n",
    "    n_episodes = 500_000\n",
    "    n_envs = 1000\n",
    "    lstm = 'seq_40'\n",
    "    part = 'train'\n",
    "    feature_extractor = 'cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/30/2023 09:37:37 AM Starting Incentive Reinforcement Learning\n",
      "05/30/2023 09:37:37 AM mappingproxy({'__dict__': <attribute '__dict__' of 'Argument' objects>,\n",
      "              '__doc__': None,\n",
      "              '__module__': '__main__',\n",
      "              '__weakref__': <attribute '__weakref__' of 'Argument' objects>,\n",
      "              'feature_extractor': 'cnn',\n",
      "              'lstm': 'seq_40',\n",
      "              'n_envs': 1000,\n",
      "              'n_episodes': 500000,\n",
      "              'n_files': 30,\n",
      "              'part': 'train',\n",
      "              'read_path': 'rl_ready_data'})\n",
      "05/30/2023 09:37:37 AM Reading data from rl_ready_data_conv/files_used_30/window_2_train.parquet\n",
      "05/30/2023 09:37:38 AM Loaded data with shape (1048575, 36)\n",
      "05/30/2023 09:37:38 AM Setting up convolution over 2T minutes\n",
      "05/30/2023 09:37:38 AM Vectorized environments created\n",
      "05/30/2023 09:37:38 AM Creating callbacks, monitors and loggerss\n",
      "05/30/2023 09:37:38 AM Using custom 1 dimensional CNN feature extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/30/2023 09:37:39 AM Model created: policy\n",
      "05/30/2023 09:37:39 AM CnnPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): CustomConv1dFeatures(\n",
      "      (cnn_1): Sequential(\n",
      "        (0): Conv1d(21, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv1d(42, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv1d(42, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): Conv1d(42, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "      )\n",
      "      (cnn_2): Sequential(\n",
      "        (0): Conv1d(42, 21, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv1d(21, 21, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "      (act): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "      (linear): Linear(in_features=210, out_features=20, bias=True)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): CustomConv1dFeatures(\n",
      "      (cnn_1): Sequential(\n",
      "        (0): Conv1d(21, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv1d(42, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv1d(42, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (7): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): Conv1d(42, 42, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "      )\n",
      "      (cnn_2): Sequential(\n",
      "        (0): Conv1d(42, 21, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv1d(21, 21, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "      (act): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "      (linear): Linear(in_features=210, out_features=20, bias=True)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "05/30/2023 09:37:39 AM Beginning training\n",
      "05/30/2023 09:37:39 AM ['n_episodes: 500000',\n",
      " 'read_path: rl_ready_data_conv/files_used_30/window_2_train.parquet',\n",
      " 'n_files: 30',\n",
      " 'n_sequences: 40',\n",
      " 'n_envs: 1000',\n",
      " 'total_timesteps: (1048575, 36)',\n",
      " 'device: cuda',\n",
      " 'tensorboard_dir: '\n",
      " 's3://dissertation-data-dmiller/reinforcement_learning_incentives_3/n_files_30/cnn_seq_40/results/2023-05-30-09-37/training_metrics',\n",
      " 'checkpoint_dir: '\n",
      " 's3://dissertation-data-dmiller/reinforcement_learning_incentives_3/n_files_30/cnn_seq_40/results/2023-05-30-09-37/checkpoints']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date_time  cum_session_event_raw  cum_session_time_raw     reward\n",
      "470565 2020-12-12 16:34:57                      7              5.882812   5.882812\n",
      "460245 2020-12-12 16:38:35                     14              9.515625   9.515625\n",
      "459417 2020-12-12 16:40:26                     18             11.351562  11.351562\n",
      "461097 2020-12-12 16:42:50                     20             13.750000  13.750000\n",
      "468471 2020-12-12 16:44:52                     24             15.781250  15.781250\n",
      "460546 2020-12-12 16:46:32                     31             17.468750  17.468750\n",
      "460776 2020-12-12 16:48:36                     37             19.531250  19.531250\n",
      "462194 2020-12-12 16:50:52                     45             21.796875  21.796875\n",
      "471020 2020-12-12 16:52:07                     51             23.046875  23.046875\n",
      "461800 2020-12-12 16:54:50                     60             25.765625  25.765625\n",
      "466696 2020-12-12 16:56:43                     68             27.656250  27.656250\n",
      "                 date_time  cum_session_event_raw  cum_session_time_raw     reward\n",
      "91118  2020-12-10 21:18:32                      1              0.000000   0.000000\n",
      "92294  2020-12-10 21:26:59                      4              8.453125   8.453125\n",
      "106732 2020-12-10 21:30:13                      5             11.664062  11.664062\n",
      "99954  2020-12-10 21:32:23                      6             13.851562  13.851562\n",
      "93465  2020-12-10 21:36:37                      9             18.078125  18.078125\n",
      "102478 2020-12-10 21:38:42                     11             20.171875  20.171875\n",
      "99700  2020-12-10 21:58:39                     13             40.125000  40.125000\n",
      "94454  2020-12-10 22:00:46                     18             42.218750  42.218750\n",
      "99527  2020-12-10 22:02:25                     21             43.875000  43.875000\n",
      "                 date_time  cum_session_event_raw  cum_session_time_raw      reward\n",
      "86551  2020-12-10 17:12:49                      5              1.750000    1.750000\n",
      "76776  2020-12-10 17:14:57                      9              3.882812    3.882812\n",
      "76831  2020-12-10 17:16:50                     11              5.785156    5.785156\n",
      "80594  2020-12-10 17:20:54                     17              9.835938    9.835938\n",
      "80929  2020-12-10 17:22:59                     20             11.914062   11.914062\n",
      "77389  2020-12-10 17:24:16                     22             13.203125   13.203125\n",
      "77729  2020-12-10 17:26:26                     25             15.367188   15.367188\n",
      "82029  2020-12-10 17:28:08                     27             17.078125   17.078125\n",
      "86948  2020-12-10 17:36:54                     29             25.828125   25.828125\n",
      "82375  2020-12-10 17:38:43                     35             27.671875   27.671875\n",
      "78333  2020-12-10 17:40:19                     38             29.250000   29.250000\n",
      "83954  2020-12-10 17:44:55                     49             33.875000   33.875000\n",
      "78880  2020-12-10 17:46:58                     53             35.906250   35.906250\n",
      "78003  2020-12-10 17:48:38                     57             37.593750   37.593750\n",
      "79548  2020-12-10 17:50:49                     62             39.750000   39.750000\n",
      "78542  2020-12-10 17:56:55                     66             45.875000   45.875000\n",
      "79950  2020-12-10 17:58:49                     68             47.750000   47.750000\n",
      "84639  2020-12-10 18:00:40                     72             49.593750   49.593750\n",
      "95026  2020-12-10 18:16:55                     78             65.875000   65.875000\n",
      "93591  2020-12-10 18:18:57                     87             67.875000   67.875000\n",
      "94935  2020-12-10 18:20:57                     94             69.875000   69.875000\n",
      "101810 2020-12-10 18:22:48                     95             71.750000   71.750000\n",
      "94542  2020-12-10 18:30:54                    103             79.875000   79.875000\n",
      "88153  2020-12-10 18:32:28                    108             81.375000   81.375000\n",
      "83094  2020-12-10 18:34:59                    116             83.937500   83.937500\n",
      "104164 2020-12-10 18:36:54                    120             85.875000   85.875000\n",
      "91184  2020-12-10 18:38:51                    128             87.812500   87.812500\n",
      "90902  2020-12-10 18:40:49                    134             89.750000   89.750000\n",
      "82308  2020-12-10 18:42:57                    139             91.875000   91.875000\n",
      "89629  2020-12-10 18:46:47                    142             95.687500   95.687500\n",
      "84510  2020-12-10 18:50:55                    148             99.875000   99.875000\n",
      "88409  2020-12-10 18:52:47                    151            101.687500  101.687500\n",
      "87987  2020-12-10 18:54:54                    156            103.875000  103.875000\n",
      "90656  2020-12-10 18:56:30                    162            105.437500  105.437500\n",
      "104370 2020-12-10 18:58:46                    168            107.687500  107.687500\n",
      "90515  2020-12-10 19:00:41                    173            109.625000  109.625000\n",
      "89122  2020-12-10 19:02:50                    180            111.812500  111.812500\n",
      "108126 2020-12-10 19:04:56                    184            113.875000  113.875000\n",
      "83778  2020-12-10 19:06:32                    189            115.437500  115.437500\n",
      "88990  2020-12-10 19:08:55                    194            117.875000  117.875000\n",
      "84055  2020-12-10 19:10:11                    198            119.125000  119.125000\n",
      "106803 2020-12-10 19:14:50                    205            123.750000  123.750000\n",
      "92579  2020-12-10 19:16:55                    212            125.875000  125.875000\n",
      "92956  2020-12-10 19:18:54                    218            127.812500  127.812500\n",
      "93120  2020-12-10 19:20:50                    223            129.750000  129.750000\n",
      "92384  2020-12-10 19:22:46                    227            131.750000  131.750000\n",
      "91390  2020-12-10 19:24:30                    228            133.375000  133.375000\n",
      "101393 2020-12-10 19:26:21                    232            135.250000  135.250000\n",
      "84722  2020-12-10 19:28:59                    237            137.875000  137.875000\n",
      "99460  2020-12-10 19:30:21                    242            139.250000  139.250000\n",
      "93364  2020-12-10 19:32:39                    245            141.625000  141.625000\n",
      "91355  2020-12-10 19:34:20                    250            143.250000  143.250000\n",
      "104782 2020-12-10 19:36:52                    256            145.750000  145.750000\n",
      "92261  2020-12-10 19:40:47                    264            149.750000  149.750000\n",
      "102725 2020-12-10 19:42:57                    269            151.875000  151.875000\n",
      "94148  2020-12-10 19:44:14                    273            153.125000  153.125000\n",
      "110013 2020-12-10 19:46:28                    276            155.375000  155.375000\n",
      "112105 2020-12-10 19:48:48                    279            157.750000  157.750000\n",
      "99323  2020-12-10 19:50:51                    284            159.750000  159.750000\n",
      "95440  2020-12-10 19:52:22                    287            161.250000  161.250000\n",
      "86926  2020-12-10 19:54:32                    294            163.500000  163.500000\n",
      "88740  2020-12-10 19:56:11                    298            165.125000  165.125000\n",
      "87250  2020-12-10 19:58:49                    302            167.750000  167.750000\n",
      "96182  2020-12-10 20:00:49                    307            169.750000  169.750000\n",
      "110418 2020-12-10 20:02:43                    311            171.625000  171.625000\n",
      "96114  2020-12-10 20:04:12                    315            173.125000  173.125000\n",
      "89436  2020-12-10 20:06:57                    319            175.875000  175.875000\n",
      "103763 2020-12-10 20:08:51                    324            177.750000  177.750000\n",
      "87909  2020-12-10 20:10:50                    332            179.750000  179.750000\n",
      "94198  2020-12-10 20:22:56                    334            191.875000  191.875000\n",
      "90310  2020-12-10 20:24:10                    336            193.125000  193.125000\n",
      "89599  2020-12-10 20:26:33                    342            195.500000  195.500000\n",
      "110129 2020-12-10 20:36:49                    349            205.750000  205.750000\n",
      "96498  2020-12-10 20:38:01                    352            207.000000  207.000000\n",
      "106977 2020-12-10 20:54:42                    359            223.625000  223.625000\n",
      "99587  2020-12-10 21:00:09                    363            229.125000  229.125000\n",
      "91964  2020-12-10 21:02:24                    365            231.375000  231.375000\n",
      "92174  2020-12-10 21:04:30                    366            233.500000  233.500000\n",
      "105746 2020-12-10 21:06:50                    369            235.750000  235.750000\n",
      "92402  2020-12-10 21:08:46                    375            237.750000  237.750000\n",
      "92282  2020-12-10 21:10:57                    383            239.875000  239.875000\n",
      "106205 2020-12-10 21:12:23                    386            241.375000  241.375000\n",
      "106406 2020-12-10 21:14:19                    391            243.250000  243.250000\n",
      "91041  2020-12-10 21:16:53                    393            245.875000  245.875000\n",
      "102118 2020-12-10 21:18:38                    400            247.625000  247.625000\n",
      "105083 2020-12-10 21:22:53                    408            251.875000  251.875000\n",
      "92145  2020-12-10 21:24:31                    412            253.500000  253.500000\n",
      "93309  2020-12-10 21:26:05                    416            255.000000  255.000000\n",
      "99953  2020-12-10 21:32:23                    423            261.250000  261.250000\n",
      "100950 2020-12-10 21:34:49                    430            263.750000  263.750000\n",
      "94335  2020-12-10 21:36:00                    435            265.000000  265.000000\n",
      "94243  2020-12-10 21:38:44                    440            267.750000  267.750000\n",
      "                 date_time  cum_session_event_raw  cum_session_time_raw     reward\n",
      "541136 2020-12-12 22:56:22                      3             27.078125  27.078125\n",
      "539575 2020-12-12 23:04:55                      4             35.625000  35.625000\n",
      "537610 2020-12-12 23:16:46                      6             47.468750  47.468750\n",
      "533202 2020-12-12 23:22:14                      7             52.968750  52.968750\n",
      "                  date_time  cum_session_event_raw  cum_session_time_raw      reward\n",
      "15246   2020-12-10 00:00:57                     38              5.367188    5.367188\n",
      "31500   2020-12-10 00:02:13                     71              0.716797    0.716797\n",
      "18797   2020-12-10 00:04:30                    100            247.125000  247.125000\n",
      "4814    2020-12-10 00:06:58                    125            249.625000  249.625000\n",
      "3711    2020-12-10 00:08:59                    152            251.625000  251.625000\n",
      "...                     ...                    ...                   ...         ...\n",
      "1041186 2021-12-06 01:30:59                 219893            192.125000  192.125000\n",
      "1042104 2021-12-06 01:32:57                 219951             20.828125   20.828125\n",
      "1046227 2021-12-06 01:34:59                 220048             75.250000   75.250000\n",
      "1042272 2021-12-06 01:36:57                 220107            165.625000  165.625000\n",
      "1043307 2021-12-06 01:38:59                 220157              4.683594    4.683594\n",
      "\n",
      "[3875 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_162/1023914865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArgument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_162/279601158.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    162\u001b[0m     ]))\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25_000_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTB_LOG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     ) -> SelfDQN:\n\u001b[0;32m--> 269\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     ) -> SelfOffPolicyAlgorithm:\n\u001b[0;32m--> 300\u001b[0;31m         total_timesteps, callback = self._setup_learn(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m_setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         return super()._setup_learn(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Avoid resetting the environment when calling ``.learn()`` consecutive times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_num_timesteps\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;31m# Retrieve unnormalized observation for saving into the buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_from_buf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_162/2111207683.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0muser_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_to_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'session_30_raw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_to_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_session_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_162/2111207683.py\u001b[0m in \u001b[0;36m_get_events\u001b[0;34m(self, user_id, session)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cum_session_event_raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cum_session_time_raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cum_session_event_raw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic_increasing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cum_session_time_raw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic_increasing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic_increasing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "main(Argument)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
