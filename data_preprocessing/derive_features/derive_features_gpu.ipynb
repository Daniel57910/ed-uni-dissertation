{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from pprint import pformat, pprint\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU:\n",
    "    import cupy as np\n",
    "    import cudf as pd\n",
    "    import pandas as cpu_pd\n",
    "else:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(linewidth=200)\n",
    "\n",
    "cpu_pd.set_option('display.max_columns', None)\n",
    "cpu_pd.set_option('display.max_rows', None)\n",
    "cpu_pd.set_option('display.width', 500)\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_LOAD_COLUMNS = [\n",
    "    'user_id',\n",
    "    'project_id',\n",
    "    'date_time',\n",
    "    'session_5_count',\n",
    "    'session_30_count',\n",
    "    'session_terminates_30_minutes',\n",
    "    'country',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_COLS = [\n",
    "    'user_id',\n",
    "    'date_time',\n",
    "    'session_30_count',\n",
    "    'session_terminates_30_minutes',\n",
    "    'cum_session_event_count',\n",
    "    'cum_session_time_minutes',\n",
    "    'expanding_click_average',\n",
    "    'cum_platform_time_minutes',\n",
    "    'cum_projects',\n",
    "    'rolling_session_time',\n",
    "    'rolling_session_events',\n",
    "    'rolling_session_gap',\n",
    "    'session_event_count',\n",
    "    'session_time_minutes'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "def encode_counts(df, logger):\n",
    "\n",
    "    logger.info('Encoding country counts')\n",
    "    country_count = df['country'].value_counts().reset_index(name='country_count').rename(columns={'index': 'country'})\n",
    " \n",
    "    logger.info('Encoding counts complete: joining users to df')\n",
    "    df = df.merge(country_count, on='country', how='left')\n",
    "    return df\n",
    "   \n",
    "def time_encodings(df):\n",
    "    \"\"\"\n",
    "    Timestamp raw encoded in units of seconds\n",
    "    \"\"\"\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['timestamp_raw'] = df['date_time'].astype(np.int64) // 10 ** 9\n",
    "    df['date_hour'] = df['date_time'].dt.hour + df['date_time'].dt.minute / 60\n",
    "    \n",
    "    df['date_hour_sin'] = np.sin(2 * np.pi * df['date_hour'] / 24)\n",
    "    df['date_hour_cos'] = np.cos(2 * np.pi * df['date_hour'] / 24)\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def rolling_time_between_events_session(df, logger):\n",
    "    logger.info('Calculating expanding session time averages')\n",
    "    df = df.reset_index()\n",
    "    df['row_count'] = df.index.values\n",
    "    expanding_window = df.set_index('row_count') \\\n",
    "        .sort_values(by=['date_time']) \\\n",
    "        .groupby(['user_id', 'session_30_count']) \\\n",
    "        .rolling(10, min_periods=1)['delta_last_event'].mean() \\\n",
    "        .reset_index().rename(columns={'delta_last_event': 'expanding_click_average'}) \\\n",
    "        .sort_values(by='row_count')\n",
    "    \n",
    "    logger.info('Expanding averages calculated: joining to df')\n",
    "    df = df.set_index('row_count').join(expanding_window[['row_count', 'expanding_click_average']].set_index('row_count'))\n",
    "    logger.info('Expanding averages joined to df')\n",
    "    df = df.sort_values(by='date_time')\n",
    "    return df\n",
    "\n",
    "def intra_session_stats(df, logger):\n",
    "    \n",
    "    logger.info('Sorting by date_time and user_id')\n",
    "    df = df.sort_values(by=['date_time', 'user_id'])\n",
    "    \n",
    "    df = df.drop_duplicates(subset=['user_id', 'date_time'], keep='first')\n",
    "    logger.info('Calculating cum_event_count')\n",
    "    df['cum_session_event_count'] = df.groupby(['user_id', 'session_30_count'])['date_time'].cumcount() + 1\n",
    "    logger.info('Cum_event_count calculated: calculating delta_last_event on cpu')\n",
    "    df['delta_last_event'] = df.groupby(['user_id', 'session_30_count'])['date_time'].diff()\n",
    "\n",
    "    df = df.sort_values(by=['date_time', 'user_id'])\n",
    "    df = df.to_pandas()\n",
    "    df['delta_last_event'] = df['delta_last_event'].dt.total_seconds()\n",
    "    df['delta_last_event'] = df['delta_last_event'].fillna(0)\n",
    "    df = pd.from_pandas(df)\n",
    "    df = df.sort_values(by=['date_time', 'user_id'])\n",
    "    df['cum_session_time_minutes'] = df.groupby(['user_id', 'session_30_count'])['delta_last_event'].cumsum()\n",
    "    df['cum_session_time_minutes'] = df['cum_session_time_minutes'] / 60\n",
    "    logger.info('Beginning rolling window 10 calculation')\n",
    "    logger.info('Rolling window 10 calculation complete: beginning expanding window calculation')\n",
    "    logger.info('Expanding window calculation complete: returning to dask')\n",
    "    return df\n",
    "\n",
    "def running_user_stats(df, logger):\n",
    "    logger.info('Calculating cumulative platform time')\n",
    "    df = df.sort_values(by=['date_time'])\n",
    "    df['cum_platform_time_minutes'] = df.groupby(['user_id'])['delta_last_event'].cumsum()\n",
    "    df['cum_platform_events'] = df.groupby(['user_id']).cumcount() + 1\n",
    "    df['cum_platform_time_minutes'] = df['cum_platform_time_minutes'] / 60\n",
    "    logger.info('Calculating cumulative platform events')\n",
    "    logger.info('Calculated cumulative platform events: calculating running unique projects')\n",
    "    \n",
    "    logger.info('Using GPU: converting to pandas')\n",
    "    logger.info('Calculating running unique projects: shifting projects to find unique')\n",
    "    \n",
    "    df['project_id'] = df['project_id'].astype(int)\n",
    "    df['user_id'] = df['user_id'].astype(int)\n",
    "    df['previous_user_project'] = df.groupby('user_id')['project_id'].shift(1)\n",
    "    df['previous_project_exists'] = df['previous_user_project'].notna()\n",
    "    \n",
    "    df['previous_user_project'] = df[['previous_user_project', 'previous_project_exists', 'project_id']].apply(\n",
    "        lambda x: x['previous_user_project'] if x['previous_project_exists'] else x['project_id'], axis=1)\n",
    "    logger.info('Calculating running unique projects: calculating unique projects')\n",
    "    \n",
    "    df['previous_user_project'] = df['previous_user_project'].astype(int)\n",
    "    df['project_change'] = df['project_id'] != df['previous_user_project']\n",
    "    \n",
    "    df['cum_projects'] = df.groupby('user_id')['project_change'].cumsum() + 1\n",
    "    \n",
    "   \n",
    "    df = df.drop(columns=['previous_user_project', 'previous_project_exists', 'project_change'])\n",
    "    logger.info('Calculated running unique projects: calculating average event time delta')\n",
    "    df = df.reset_index()\n",
    "    df['row_count'] = df.index.values\n",
    "    \n",
    "    average_event_time = df.set_index('row_count') \\\n",
    "        .sort_values(by=['date_time']) \\\n",
    "        .groupby('user_id') \\\n",
    "        .rolling(1000, min_periods=1)['delta_last_event'].mean() \\\n",
    "        .reset_index().rename(columns={'delta_last_event': 'average_event_time'}) \\\n",
    "        .sort_values(by='row_count')\n",
    "    df = df.set_index('row_count').join(average_event_time[['row_count', 'average_event_time']].set_index('row_count'))\n",
    "    logger.info('Calculated average event time delta')\n",
    "    return df\n",
    "\n",
    "\n",
    "def time_from_previous_session_minutes(session_inflection_times, logger):\n",
    "    session_inflection_times = session_inflection_times.sort_values(by=['session_30_count', 'user_id'])\n",
    "    \n",
    "    session_inflection_times['previous_session_end'] = session_inflection_times.groupby(['user_id'])['date_time_max'].shift(1)\n",
    "    session_inflection_times['time_between_session_minutes'] = (session_inflection_times['date_time_min'] - session_inflection_times['previous_session_end']).dt.total_seconds() / 60\n",
    "    session_inflection_times['time_between_session_minutes'] = session_inflection_times['time_between_session_minutes'].fillna(0)\n",
    "    return session_inflection_times[['user_id', 'session_30_count', 'time_between_session_minutes', 'date_time_min', 'date_time_max']]\n",
    "\n",
    "def rolling_average_session_statistics(df, session_inflection_times, logger):\n",
    " \n",
    "    logger.info('Session inflection times calculated: calculating expanding session time')\n",
    "    average_session_minutes = session_inflection_times.sort_values(by=['session_30_count', 'user_id']) \\\n",
    "    .set_index(['session_30_count', 'date_time_min', 'date_time_max']) \\\n",
    "    .groupby(['user_id']) \\\n",
    "    ['session_time_minutes'] \\\n",
    "    .rolling(10, min_periods=1, closed='left') \\\n",
    "    .mean() \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'session_time_minutes': 'rolling_session_time'})\n",
    "   \n",
    "    average_session_minutes['rolling_session_time'] = average_session_minutes['rolling_session_time'].fillna(0)\n",
    "    logger.info('Calculating average events per session')\n",
    "    average_events_session = session_inflection_times.sort_values(by=['session_30_count', 'user_id']) \\\n",
    "        .set_index(['session_30_count', 'date_time_min', 'date_time_max']) \\\n",
    "        .groupby(['user_id']) \\\n",
    "        ['session_event_count'] \\\n",
    "        .rolling(10, min_periods=1, closed='left') \\\n",
    "        .mean() \\\n",
    "        .reset_index() \\\n",
    "        .rename(columns={'session_event_count': 'rolling_session_events'})\n",
    "    \n",
    "    average_events_session['rolling_session_events'] = average_events_session['rolling_session_events'].fillna(0)\n",
    "    \n",
    "    logger.info('Calculating time from previous session')\n",
    "    time_between_session = time_from_previous_session_minutes(session_inflection_times, logger)\n",
    "    \n",
    "    time_between_session = time_between_session.sort_values(by=['session_30_count', 'user_id']) \\\n",
    "        .set_index(['session_30_count']) \\\n",
    "        .groupby(['user_id']) \\\n",
    "        ['time_between_session_minutes'] \\\n",
    "        .rolling(5, min_periods=1) \\\n",
    "        .mean() \\\n",
    "        .reset_index() \\\n",
    "        .rename(columns={'time_between_session_minutes': 'rolling_session_gap'})\n",
    "\n",
    "    logger.info('Joining dataframes')\n",
    "   \n",
    "    session_stats = cpu_pd.merge(average_events_session, average_session_minutes, on=['user_id', 'session_30_count']) \n",
    "    session_stats = cpu_pd.merge(session_stats, session_inflection_times, on=['user_id', 'session_30_count'])\n",
    "    session_stats = cpu_pd.merge(session_stats, time_between_session, on=['user_id', 'session_30_count'])\n",
    "    session_stats = pd.from_pandas(session_stats)\n",
    "    \n",
    "    df = pd.merge(df, session_stats[['user_id', 'session_30_count', 'rolling_session_time', 'rolling_session_events', 'rolling_session_gap', 'session_event_count', 'session_time_minutes', 'rolling_session_gap']], on=['user_id', 'session_30_count'])\n",
    "    logger.info('Dataframes joined::returning')\n",
    "    return df\n",
    "\n",
    "\n",
    "def assign_metadata(df, logger):\n",
    "    logger.info(f'Obtaining global session time and user events')\n",
    "    global_session_time = df.groupby('user_id')['cum_platform_time_minutes'].max().reset_index().rename(columns={'cum_platform_time_minutes': 'global_session_time_minutes'})\n",
    "    user_count = df['user_id'].value_counts().reset_index(name='global_events_user').rename(columns={'index': 'user_id'})\n",
    "    \n",
    "    logger.info('Joining session_time to df')\n",
    "    df = pd.merge(df, global_session_time, on='user_id', how='left')\n",
    "    logger.info('Joining user_count to df')\n",
    "    df = pd.merge(df, user_count, on='user_id', how='left')\n",
    "   \n",
    "    df['cum_session_event_raw'] = df['cum_session_event_count']\n",
    "    df['cum_platform_event_raw'] = df['cum_platform_events']\n",
    "    df['session_30_count_raw'] = df['session_30_count']\n",
    "    df['cum_session_time_raw'] = df['cum_session_time_minutes']\n",
    "    logger.info('Assigning date_metadata')\n",
    "    df['year'] = df['date_time'].dt.year\n",
    "    df['month'] = df['date_time'].dt.month\n",
    "    df['day'] = df['date_time'].dt.day\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    df['minute'] = df['date_time'].dt.minute\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def hash_user_id(df):\n",
    "    user_id = df[['user_id']].drop_duplicates().reset_index().rename(columns={'index': 'user_id_hash'})\n",
    "    df = pd.merge(df, user_id, on='user_id')\n",
    "    df = df.drop(columns=['user_id'])\n",
    "    df = df.rename(columns={'user_id_hash': 'user_id'})\n",
    "    return df\n",
    "\n",
    "def generate_summary_session_stats(df, logger):\n",
    "    logger.info('Generating session statistics')\n",
    "    session_inflection_statistics = df.groupby(['user_id', 'session_30_count']).agg({'date_time': ['min', 'max', 'count']}).reset_index()\n",
    "    session_inflection_statistics.columns = ['user_id', 'session_30_count', 'date_time_min', 'date_time_max', 'session_event_count']\n",
    "    session_inflection_statistics = session_inflection_statistics.to_pandas()\n",
    "    session_inflection_statistics['session_time_minutes'] = (session_inflection_statistics['date_time_max'] - session_inflection_statistics['date_time_min']).dt.total_seconds() / 60\n",
    "    return session_inflection_statistics\n",
    "\n",
    "\n",
    "def _pretty_print_columns(df):\n",
    "    for col in df.columns:\n",
    "        print(f'    \"{col}\"')\n",
    "def main(args):\n",
    "    #\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    logger =  get_logger()\n",
    "    logger.info(f'Running feature calculation with args')\n",
    "    logger.info(pformat(args.__dict__))\n",
    "\n",
    "\n",
    "    \n",
    "    logger.info(f'Loading data from {args.input_path}')\n",
    "    df = pd.read_parquet(args.input_path, columns=INITIAL_LOAD_COLUMNS)\n",
    "    df = hash_user_id(df)\n",
    "    logger.info(f'Loaded data: shape = {df.shape}, min_date, max_date: {df.date_time.min()}, {df.date_time.max()}')\n",
    "    label_count = df[df['session_terminates_30_minutes'] == True].shape[0] / df.shape[0]\n",
    "    logger.info(f'Perc ending in 30 minutes: {label_count}')\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    logger.info(f'Sorting data by date_time')\n",
    "    df = df.sort_values(by='date_time')\n",
    "    logger.info('Finished sorting data: encoding value counts')\n",
    "    df = encode_counts(df, logger)\n",
    "    logger.info('Finished encoding value counts: encoding time features')\n",
    "    df = time_encodings(df) \n",
    "   \n",
    "    logger.info('Time encodings complete: encoding categorical features')\n",
    "    \n",
    "    \n",
    "    logger.info('Categorical features encoded: calculating intra-session stats')\n",
    "    df = intra_session_stats(df, logger)\n",
    "    logger.info('Beginning rolling window 10 calculation')\n",
    "    \n",
    "    df = rolling_time_between_events_session(df, logger)\n",
    "    logger.info('Rolling window 10 calculation complete: beginning expanding window calculation')\n",
    "    \n",
    "    logger.info(f'Calculating running user stats')\n",
    "    df = running_user_stats(df, logger)\n",
    "    logger.info('Calculating between session stats')\n",
    "   \n",
    "\n",
    "    session_inflection_times = generate_summary_session_stats(df, logger)\n",
    "    logger.info('Session inflection times calculated: columns')\n",
    "    logger.info(pformat(session_inflection_times.columns))\n",
    "    df = rolling_average_session_statistics(df, session_inflection_times, logger)\n",
    "    logger.info('Time within session and average session clicks calculated:: calculating time between session')\n",
    "    df['session_30_raw'] = df['session_30_count']\n",
    "\n",
    "    logger.info('Assigning metadata')\n",
    "    df = assign_metadata(df, logger)\n",
    "    logger.info('Metadata assigned: dropping columns')\n",
    "    \n",
    "    logger.info('Returning df to dask for writing to disk')\n",
    "       \n",
    "    output_path = os.path.join(args.output_path, f'files_used_{args.data_subset}')\n",
    "    logger.info(f'Writing to {output_path}')\n",
    "    \n",
    "    logger.info(f'df converted to dask: shape -> {df.shape}')\n",
    "    logger.info(f'Final out columns:')\n",
    "    _pretty_print_columns(df)\n",
    "\n",
    "    df = df.sort_values(by='date_time').reset_index(drop=True).to_parquet(output_path)\n",
    "\n",
    "    logger.info('Finished writing to disk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self, data_subset):\n",
    "        self.input_path = f'labelled_session_count_data/files_used_{data_subset}'\n",
    "        self.output_path = 'calculated_features/'\n",
    "        self.data_subset = data_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_subset in [2, 10, 30]:\n",
    "    args = Arguments(data_subset)\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('calculated_features/files_used_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_30_count</th>\n",
       "      <th>cum_session_event_raw</th>\n",
       "      <th>cum_session_time_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  session_30_count  cum_session_event_raw  cum_session_time_raw\n",
       "0        0                 1                      1              0.000000\n",
       "1        1                 1                      1              0.000000\n",
       "2        0                 1                      2              0.033333\n",
       "3        2                 1                      1              0.000000\n",
       "4        0                 1                      3              0.066667\n",
       "5        1                 1                      2              0.066667\n",
       "6        0                 1                      4              0.100000\n",
       "7        2                 1                      2              0.066667\n",
       "8        8                 1                      1              0.000000\n",
       "9        0                 1                      5              0.116667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['user_id', 'session_30_count', 'cum_session_event_raw', 'cum_session_time_raw']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cum_session_time_raw    807.95\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['cum_session_time_raw']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1da7ff4cdcccf44e7e228c52b231f7d5c5854d5618af555ed3871fd5cba609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
