{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load session_calculate.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "import cudf\n",
    "import dask_cudf as dd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "TEST_U_ID = [2373355, 10, 4301]\n",
    "\n",
    "OUT_COLUMNS = [\n",
    "    'user_id',\n",
    "    'project_id',\n",
    "    'date_time',\n",
    "    'session_5_count',\n",
    "    'session_30_count',\n",
    "    'session_terminates_30_minutes',\n",
    "    'country',\n",
    "]\n",
    "\n",
    "from pprint import pformat\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "class SessionCalculate:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    def __init__(self, df, write_path, use_gpu, test_env) -> None:\n",
    "        self.df = df\n",
    "        self.write_path = write_path\n",
    "        self.use_gpu = use_gpu\n",
    "        self.test_env = test_env\n",
    "    \n",
    "    def calculate_inflections(self):\n",
    "       \n",
    "        self.logger.info('Calculating subsequent date time')\n",
    "        self.df['next_date_time'] = self.df.groupby('user_id')['date_time'].shift(-1)\n",
    "        self.df = self.df.drop_duplicates(subset=['user_id', 'date_time'], keep='last').reset_index()\n",
    "        if self.use_gpu:\n",
    "            self.logger.info('Bringing to CPU for second calculation')\n",
    "            self.df = self.df.to_pandas()\n",
    "           \n",
    "            \n",
    "        self.df['diff_seconds'] = (self.df['next_date_time'] - self.df['date_time']).apply(lambda x: x.total_seconds())\n",
    "        \n",
    "        self.logger.info('Diff seconds calculated')\n",
    "        if self.use_gpu:\n",
    "            self.logger.info('Bringing back to GPU for final calculations')\n",
    "            self.df = cudf.from_pandas(self.df)\n",
    "\n",
    "        self.df['diff_minutes'] = (self.df['diff_seconds'] / 60)\n",
    "        self.df['session_5'] = (self.df['diff_minutes'] < 5)\n",
    "        self.df['session_30'] = self.df['diff_minutes'] < 30\n",
    "        \n",
    "        self.df['session_30'] = self.df['session_30'].fillna(False)\n",
    "        self.df['session_5'] = self.df['session_5'].fillna(False)        \n",
    "        self.logger.info(f'Labels calculated: removing rows with diff seconds > 0')\n",
    "       \n",
    "        \n",
    "\n",
    "        self.logger.info(f'Number of rows following drop: {self.df.shape[0]}')\n",
    "        self.logger.info(f'Sorting rows by date time and applying row count')\n",
    "        self.df = self.df.sort_values(['date_time']).reset_index()\n",
    "        self.df['row_count'] = self.df.index.values\n",
    "        self.logger.info(f'Sorted rows and applied row count on updated index')  \n",
    "        self.logger.info('Calculating inflection points')\n",
    "        self.df['user_id'] = self.df['user_id'].astype('int32')\n",
    "        \n",
    "       \n",
    "        inflections_5_merge = self.df[self.df['session_5'] == False].sort_values(by=['date_time'])\n",
    "        inflections_30_merge = self.df[self.df['session_30'] == False].sort_values(by=['date_time']) \n",
    "     \n",
    "        self.logger.info('Calculating session 5 inflections') \n",
    "        inflections_5_merge['session_5'] = inflections_5_merge.groupby('user_id').cumcount() + 1\n",
    "        inflections_5_merge = inflections_5_merge.rename(columns={'session_5': 'session_5_count'})\n",
    "        \n",
    "        self.logger.info('Calculating session 30 inflections')\n",
    "        inflections_30_merge['session_30'] = inflections_30_merge.groupby('user_id').cumcount() + 1\n",
    "        inflections_30_merge = inflections_30_merge.rename(columns={'session_30': 'session_30_count'})\n",
    "        \n",
    "        inflections_5_merge = inflections_5_merge[['user_id', 'date_time', 'row_count', 'session_5_count']].sort_values(by=['row_count', 'user_id'])\n",
    "        inflections_30_merge = inflections_30_merge[['user_id', 'date_time', 'row_count', 'session_30_count']].sort_values(by=['row_count', 'user_id'])\n",
    "        inflections_5_merge = inflections_5_merge.drop(columns=['date_time'])\n",
    "        \n",
    "        inflections_30_merge = inflections_30_merge.rename(columns={'date_time': 'session_end_time'})\n",
    "\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            self.logger.info('Bringing back to GPU for labelling')\n",
    "            self.df, inflections_5_merge, inflections_30_merge = self.df.to_pandas(), inflections_5_merge.to_pandas(), inflections_30_merge.to_pandas()\n",
    "            self.df = self.df.sort_values(by=['row_count', 'user_id'])\n",
    "            self.df = pd.merge_asof(self.df, inflections_5_merge, on='row_count', by='user_id', direction='forward')\n",
    "            self.df = pd.merge_asof(self.df, inflections_30_merge, on='row_count', by='user_id', direction='forward')\n",
    "            self.df['session_terminates_30_minutes'] = (self.df['session_end_time'] - self.df['date_time']).apply(lambda x: x.total_seconds() / 60) < 30\n",
    "            self.df = cudf.from_pandas(self.df)\n",
    "        else:\n",
    "            self.logger.info('Labelling on CPU')\n",
    "            self.df = pd.merge_asof(self.df.sort_values(by=['row_count', 'user_id']), inflections_5_merge, on='row_count', by='user_id', direction='forward')\n",
    "\n",
    "            self.df = pd.merge_asof(self.df.sort_values(by=['row_count', 'user_id']), inflections_5_merge, on='row_count', by='user_id', direction='forward')\n",
    "            self.df = pd.merge_asof(self.df.sort_values(by=['row_count', 'user_id']), inflections_30_merge, on='row_count', by='user_id', direction='forward') \n",
    "            self.df['session_terminates_30_minutes'] = (self.df['session_end_time'] - self.df['date_time']).apply(lambda x: x.total_seconds() / 60) < 30\n",
    " \n",
    "        self.logger.info('Inflections calculated')\n",
    " \n",
    "        session_end_30_minutes = self.df[self.df['session_terminates_30_minutes'] == False].shape[0]\n",
    "        self.logger.info(f'Percent sessions end in 30 minutes: {session_end_30_minutes / self.df.shape[0]}')\n",
    "        self.logger.info(f'Columns for df') \n",
    "        self.logger.info(pformat(self.df.columns))\n",
    "        \n",
    "        \n",
    "    def write_inflections_parquet(self):\n",
    "    \n",
    "\n",
    "        self.logger.info(f'Writing inflections to {self.write_path}')\n",
    "\n",
    "        self.df = self.df[OUT_COLUMNS].sort_values(by=['date_time', 'user_id']).to_parquet(self.write_path)\n",
    "        # write_path = self.write_path + '.parquet.gzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_COLUMNS = [\n",
    "    \"project_id\",\n",
    "    \"user_id\",\n",
    "    \"country\",  \n",
    "    \"date_time\",\n",
    "]\n",
    "\n",
    "def get_logger():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    pd.set_option('display.width', 500)\n",
    "\n",
    "    logger = get_logger()\n",
    "    read_path, write_path, n_files = args.read_path, args.write_path, args.n_files\n",
    "    logger.info(f'Read: {read_path}, Write: {write_path}, N Files: {n_files}')\n",
    "    files_to_read = sorted(list(glob.iglob(f'{read_path}/*.parquet')))\n",
    "    logger.info(f'Found {len(files_to_read)} files to read')\n",
    "    if args.n_files < 30:\n",
    "        logger.info(f'Loading partial data for testing: {args.n_files}')\n",
    "        df_list = []\n",
    "        for file in files_to_read[:args.n_files]:\n",
    "            df_list.append(cudf.read_parquet(file, usecols=LOAD_COLUMNS))\n",
    "        df = cudf.concat(df_list)\n",
    "    else:\n",
    "        df = cudf.read_parquet(args.read_path, usecols=LOAD_COLUMNS)\n",
    "        \n",
    "    df['date_time'] = cudf.to_datetime(df['date_time'])\n",
    "    df = df.sort_values(by=['date_time'])\n",
    "    \n",
    "    write_path = os.path.join(write_path, f'files_used_{n_files}')\n",
    "    session_calculator = SessionCalculate(df, write_path, args.use_gpu, args.test_env)\n",
    "    session_calculator.calculate_inflections()    \n",
    "\n",
    "    session_calculator.write_inflections_parquet()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    read_path = 'labelled_session_count_data'\n",
    "    write_path = 'labelled_session_count_data_2'\n",
    "    n_files = 30\n",
    "    use_gpu = True\n",
    "\n",
    "    test_env = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 14:00:04,208 - __main__ - INFO - Read: labelled_session_count_data, Write: labelled_session_count_data_2, N Files: 30\n",
      "2023-03-28 14:00:04,210 - __main__ - INFO - Found 30 files to read\n",
      "2023-03-28 14:00:07,323 - __main__ - INFO - Calculating subsequent date time\n",
      "2023-03-28 14:00:07,484 - __main__ - INFO - Bringing to CPU for second calculation\n",
      "2023-03-28 14:00:07,486 - numba.cuda.cudadrv.driver - INFO - init\n",
      "2023-03-28 14:01:17,079 - __main__ - INFO - Diff seconds calculated\n",
      "2023-03-28 14:01:17,079 - __main__ - INFO - Bringing back to GPU for final calculations\n",
      "2023-03-28 14:01:19,336 - __main__ - INFO - Labels calculated: removing rows with diff seconds > 0\n",
      "2023-03-28 14:01:19,337 - __main__ - INFO - Number of rows following drop: 38500990\n",
      "2023-03-28 14:01:19,337 - __main__ - INFO - Sorting rows by date time and applying row count\n",
      "2023-03-28 14:01:19,397 - __main__ - INFO - Sorted rows and applied row count on updated index\n",
      "2023-03-28 14:01:19,397 - __main__ - INFO - Calculating inflection points\n",
      "2023-03-28 14:01:19,482 - __main__ - INFO - Calculating session 5 inflections\n",
      "2023-03-28 14:01:19,522 - __main__ - INFO - Calculating session 30 inflections\n",
      "2023-03-28 14:01:19,556 - __main__ - INFO - Bringing back to GPU for labelling\n",
      "2023-03-28 14:03:18,499 - __main__ - INFO - Inflections calculated\n",
      "2023-03-28 14:03:18,521 - __main__ - INFO - Percent sessions end in 30 minutes: 0.4033570305594739\n",
      "2023-03-28 14:03:18,522 - __main__ - INFO - Columns for df\n",
      "2023-03-28 14:03:18,522 - __main__ - INFO - Index(['index', '__null_dask_index__', 'project_id', 'workflow_id', 'user_id', 'country', 'date_time', 'diff_minutes', 'label_5', 'label_30', 'row_count', 'session_5', 'session_30', 'next_date_time', 'diff_seconds', 'session_5_count', 'session_end_time', 'session_30_count', 'session_terminates_30_minutes'], dtype='object')\n",
      "2023-03-28 14:03:18,525 - __main__ - INFO - Writing inflections to labelled_session_count_data_2/files_used_30\n"
     ]
    }
   ],
   "source": [
    "main(Arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_parquet('labelled_session_count_data_2/files_used_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.session_5_count.count() / df.shape[0])\n",
    "display(df.session_30_count.count() / df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.596643\n",
       "False    0.403357\n",
       "Name: session_terminates_30_minutes, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.session_terminates_30_minutes.value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38500990, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
