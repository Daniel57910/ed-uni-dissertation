{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.111 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113 --quiet\n",
    "!python -m pip install boto3 python-dotenv gputil --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INITIAL_LOAD_COLUMNS = [\n",
    "    'user_id',\n",
    "    'project_id',\n",
    "    'date_time',\n",
    "    'session_5_count',\n",
    "    'session_30_count',\n",
    "    'session_terminates_30_minutes',\n",
    "    'country',\n",
    "]\n",
    "\n",
    "LABEL = [\n",
    "    \"session_terminates_30_minutes\"\n",
    "]\n",
    "\n",
    "\n",
    "METADATA = [\n",
    "    \"user_id\",\n",
    "    \"session_30_raw\",\n",
    "    \"cum_session_event_raw\",\n",
    "    \"cum_session_time_raw\",\n",
    "    \"cum_platform_event_raw\",\n",
    "    \"global_events_user\",\n",
    "    \"global_session_time_minutes\",\n",
    "]\n",
    "\n",
    "DATE_TIME = [\n",
    "    \"date_time\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"hour\",\n",
    "    \"minute\"\n",
    "]\n",
    "\n",
    "OUT_FEATURE_COLUMNS = [\n",
    "    \"country_count\",\n",
    "    \"timestamp_raw\",\n",
    "    \"date_hour_sin\",\n",
    "    \n",
    "    \"date_hour_cos\",\n",
    "    \"session_5_count\",\n",
    "    \"session_30_count\",\n",
    "    \n",
    "    \"cum_session_event_count\",\n",
    "    \"delta_last_event\",\n",
    "    \"cum_session_time_minutes\",\n",
    "    \n",
    "    \"expanding_click_average\",\n",
    "    \"cum_platform_time_minutes\",\n",
    "    \"cum_platform_events\",\n",
    "    \n",
    "    \"cum_projects\",\n",
    "    \"average_event_time\",\n",
    "    \"rolling_session_time\",\n",
    "    \n",
    "    \"rolling_session_events\",\n",
    "    \"rolling_session_gap\",\n",
    "    \"session_event_count\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "GROUPBY_COLS = ['user_id']\n",
    "\n",
    "TORCH_LOAD_COLS = LABEL + METADATA + DATE_TIME + OUT_FEATURE_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as gpu_pd\n",
    "from cuml.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as cpu_np\n",
    "import cupy as gpu_np\n",
    "import pandas as cpu_pd\n",
    "from pprint import pformat\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import boto3\n",
    "import os\n",
    "import numpy \n",
    "import logging\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionizeData:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    def __init__(self, df, max_sequence_index, write_path, load_cols, feature_cols, grouper, save_s3=True):\n",
    "        self.df = df\n",
    "        self.max_sequence_index = max_sequence_index + 1\n",
    "        self.min_sequence_index = self.max_sequence_index - 10\n",
    "        self.device = self._device()\n",
    "        self.sequences = cpu_np.arange(self.min_sequence_index, self.max_sequence_index).tolist()\n",
    "        self.seq_container = []\n",
    "        self.torch_sequences = None\n",
    "        self.output_path = write_path\n",
    "        self.save_s3 = save_s3\n",
    "        self.load_columns = load_cols\n",
    "        self.feature_cols = feature_cols\n",
    "        self.grouper = grouper\n",
    "        \n",
    "\n",
    "    def _device(self):\n",
    "        return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def _sequence_lazy(self):\n",
    "         return next(self._lazy_load_shifted_index())\n",
    "\n",
    "    def _shifters(self):\n",
    "        for _ in range(self.min_sequence_index, self.max_sequence_index):\n",
    "            self.logger.info(f'Loading sequence: {_} -> {self.max_sequence_index}')\n",
    "            self.seq_container.append(self._sequence_lazy())\n",
    "        if torch.cuda.is_available():\n",
    "            GPUtil.showUtilization()\n",
    "\n",
    "        sequences = torch.cat(self.seq_container, dim=1).half()\n",
    "        return sequences\n",
    "\n",
    "    def generate_sequence(self):\n",
    "\n",
    "        self.logger.info(f'Generating shifted clickstreams from {self.min_sequence_index} -> {self.max_sequence_index}')\n",
    "        sequence = self._shifters()\n",
    "\n",
    "        self.logger.info(f'Shifter shape: {sequence.shape}')\n",
    "        \n",
    "\n",
    "        self.logger.info(f'Loading intial clickstream to {self.device}')\n",
    "\n",
    "        if self.max_sequence_index == 11:\n",
    "            self.logger.info('Initial clickstream writing to disk')\n",
    "            initial_clickstream = self.df[self.load_columns].values.astype(gpu_np.float32)\n",
    "            self._sequence_to_disk(initial_clickstream, 0)\n",
    "\n",
    "        self.logger.info(f'Writing sequence to disk: {self.max_sequence_index - 1}')\n",
    "        self._sequence_to_disk(sequence.cpu().numpy(), self.max_sequence_index - 1)\n",
    "\n",
    "\n",
    "    def _sequence_to_disk(self, partition, sequence_index):\n",
    "        if self.save_s3:\n",
    "            s3_client = boto3.client(\n",
    "                's3',\n",
    "                aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "                aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],\n",
    "            )\n",
    "\n",
    "        if not os.path.exists(self.output_path):\n",
    "            os.makedirs(self.output_path)\n",
    "\n",
    "        partition_path = os.path.join(self.output_path, f'sequence_index_{sequence_index}.npz')\n",
    "        self.logger.info(f'Saving to disk: {partition_path}')\n",
    "        numpy.savez_compressed(partition_path, partition)\n",
    "\n",
    "        if self.save_s3:\n",
    "            self.logger.info(f'Uploading to s3: dissertation-data-dmiller/{partition_path}')\n",
    "            s3_client.upload_file(partition_path, 'dissertation-data-dmiller', partition_path)\n",
    "\n",
    "    def _lazy_load_shifted_index(self):\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        indx = self.sequences.pop(0)\n",
    "        torch_container = []\n",
    "        for col in self.feature_cols:\n",
    "            sequence = self.df.groupby(self.grouper)[col].shift(indx).fillna(0).values.astype(gpu_np.float16)\n",
    "            sequence_tensor = torch.tensor(sequence).to(self.device).half()\n",
    "            torch_container.append(sequence_tensor.unsqueeze(1))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        yield torch.cat(torch_container, dim=1).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=4, linewidth=400)\n",
    "\n",
    "cpu_np.set_printoptions(suppress=True)\n",
    "cpu_np.set_printoptions(precision=4)\n",
    "\n",
    "def get_logger():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def scale_feature_cols(df, scaler, scaler_columns):\n",
    "    df[scaler_columns] = scaler.fit_transform(df[scaler_columns])\n",
    "    return df\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    logger = get_logger()\n",
    "    logger.info('Starting sessionize_users_cpu.py with arguments')\n",
    "    logger.info(pformat(args.__dict__))\n",
    "    \n",
    "    data_read = os.path.join(args.input_path, f'files_used_{args.data_subset}')\n",
    "\n",
    "    logger.info(f'Reading data from {data_read}')\n",
    "    df = gpu_pd.read_parquet(data_read, columns=TORCH_LOAD_COLS)\n",
    "    logger.info(f'Data read: {df.shape}')\n",
    "    logger.info('Casting date time and sorting by date time')\n",
    "    df['date_time'] = gpu_pd.to_datetime(df['date_time'])\n",
    "    df = df.sort_values(by=['date_time'])\n",
    "    logger.info('Data read: scaling scaler columns')\n",
    "    df = scale_feature_cols(df, MinMaxScaler(), OUT_FEATURE_COLUMNS)\n",
    "    logger.info('Scaling complete: implement sessionize')\n",
    "    \n",
    "    for seq_index in args.seq_list:\n",
    "\n",
    "        sessionize = SessionizeData(\n",
    "            df,\n",
    "            seq_index,\n",
    "            os.path.join(args.output_path, f'files_used_{args.data_subset}'),\n",
    "            [col for col in TORCH_LOAD_COLS if col != 'date_time'],\n",
    "            OUT_FEATURE_COLUMNS,\n",
    "            GROUPBY_COLS,\n",
    "            args.save_s3\n",
    "        )\n",
    "    \n",
    "        logger.info(f'Generating sequence for {seq_index}')\n",
    "        sessionize.generate_sequence()\n",
    "    \n",
    "    logger.info(f'Sessionize complete for sequences {args.seq_list}')\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 15:09:12,247 - __main__ - INFO - Starting sessionize_users_cpu.py with arguments\n",
      "2023-04-12 15:09:12,249 - __main__ - INFO - {'data_subset': 2}\n",
      "2023-04-12 15:09:12,249 - __main__ - INFO - Reading data from calculated_features/files_used_2\n",
      "2023-04-12 15:09:18,374 - __main__ - INFO - Data read: (2566734, 32)\n",
      "2023-04-12 15:09:18,375 - __main__ - INFO - Casting date time and sorting by date time\n",
      "2023-04-12 15:09:18,389 - __main__ - INFO - Data read: scaling scaler columns\n",
      "2023-04-12 15:09:22,002 - __main__ - INFO - Scaling complete: implement sessionize\n",
      "2023-04-12 15:09:22,004 - __main__ - INFO - Generating sequence for 10\n",
      "2023-04-12 15:09:22,005 - __main__ - INFO - Generating shifted clickstreams from 1 -> 11\n",
      "2023-04-12 15:09:22,005 - __main__ - INFO - Loading sequence: 1 -> 11\n",
      "2023-04-12 15:09:26,587 - __main__ - INFO - Loading sequence: 2 -> 11\n",
      "2023-04-12 15:09:26,870 - __main__ - INFO - Loading sequence: 3 -> 11\n",
      "2023-04-12 15:09:27,145 - __main__ - INFO - Loading sequence: 4 -> 11\n",
      "2023-04-12 15:09:27,420 - __main__ - INFO - Loading sequence: 5 -> 11\n",
      "2023-04-12 15:09:27,693 - __main__ - INFO - Loading sequence: 6 -> 11\n",
      "2023-04-12 15:09:27,973 - __main__ - INFO - Loading sequence: 7 -> 11\n",
      "2023-04-12 15:09:28,247 - __main__ - INFO - Loading sequence: 8 -> 11\n",
      "2023-04-12 15:09:28,521 - __main__ - INFO - Loading sequence: 9 -> 11\n",
      "2023-04-12 15:09:28,797 - __main__ - INFO - Loading sequence: 10 -> 11\n",
      "2023-04-12 15:09:29,216 - __main__ - INFO - Shifter shape: torch.Size([2566734, 180])\n",
      "2023-04-12 15:09:29,217 - __main__ - INFO - Loading intial clickstream to cuda\n",
      "2023-04-12 15:09:29,217 - __main__ - INFO - Initial clickstream writing to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 77% |  8% |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 15:09:29,834 - __main__ - INFO - Saving to disk: torch_ready_data/files_used_2/sequence_index_0.npz\n",
      "2023-04-12 15:09:39,337 - __main__ - INFO - Uploading to s3: dissertation-data-dmiller/torch_ready_data/files_used_2/sequence_index_0.npz\n",
      "2023-04-12 15:09:45,156 - __main__ - INFO - Writing sequence to disk: 10\n",
      "2023-04-12 15:09:45,761 - __main__ - INFO - Saving to disk: torch_ready_data/files_used_2/sequence_index_10.npz\n",
      "2023-04-12 15:09:57,763 - __main__ - INFO - Uploading to s3: dissertation-data-dmiller/torch_ready_data/files_used_2/sequence_index_10.npz\n",
      "2023-04-12 15:10:05,770 - __main__ - INFO - Sessionize complete for sequences [10]\n",
      "2023-04-12 15:10:05,773 - __main__ - INFO - Starting sessionize_users_cpu.py with arguments\n",
      "2023-04-12 15:10:05,773 - __main__ - INFO - {'data_subset': 10}\n",
      "2023-04-12 15:10:05,774 - __main__ - INFO - Reading data from calculated_features/files_used_10\n",
      "2023-04-12 15:10:08,161 - __main__ - INFO - Data read: (12833662, 32)\n",
      "2023-04-12 15:10:08,162 - __main__ - INFO - Casting date time and sorting by date time\n",
      "2023-04-12 15:10:08,192 - __main__ - INFO - Data read: scaling scaler columns\n",
      "2023-04-12 15:10:10,345 - __main__ - INFO - Scaling complete: implement sessionize\n",
      "2023-04-12 15:10:10,346 - __main__ - INFO - Generating sequence for 10\n",
      "2023-04-12 15:10:10,346 - __main__ - INFO - Generating shifted clickstreams from 1 -> 11\n",
      "2023-04-12 15:10:10,346 - __main__ - INFO - Loading sequence: 1 -> 11\n",
      "2023-04-12 15:10:11,248 - __main__ - INFO - Loading sequence: 2 -> 11\n",
      "2023-04-12 15:10:12,147 - __main__ - INFO - Loading sequence: 3 -> 11\n",
      "2023-04-12 15:10:13,063 - __main__ - INFO - Loading sequence: 4 -> 11\n",
      "2023-04-12 15:10:13,988 - __main__ - INFO - Loading sequence: 5 -> 11\n",
      "2023-04-12 15:10:14,896 - __main__ - INFO - Loading sequence: 6 -> 11\n",
      "2023-04-12 15:10:15,804 - __main__ - INFO - Loading sequence: 7 -> 11\n",
      "2023-04-12 15:10:16,709 - __main__ - INFO - Loading sequence: 8 -> 11\n",
      "2023-04-12 15:10:17,605 - __main__ - INFO - Loading sequence: 9 -> 11\n",
      "2023-04-12 15:10:18,515 - __main__ - INFO - Loading sequence: 10 -> 11\n",
      "2023-04-12 15:10:19,567 - __main__ - INFO - Shifter shape: torch.Size([12833662, 180])\n",
      "2023-04-12 15:10:19,570 - __main__ - INFO - Loading intial clickstream to cuda\n",
      "2023-04-12 15:10:19,570 - __main__ - INFO - Initial clickstream writing to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 73% | 14% |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 15:10:20,510 - __main__ - INFO - Saving to disk: torch_ready_data/files_used_10/sequence_index_0.npz\n",
      "2023-04-12 15:11:05,438 - __main__ - INFO - Uploading to s3: dissertation-data-dmiller/torch_ready_data/files_used_10/sequence_index_0.npz\n",
      "2023-04-12 15:11:15,424 - __main__ - INFO - Writing sequence to disk: 10\n",
      "2023-04-12 15:11:18,509 - __main__ - INFO - Saving to disk: torch_ready_data/files_used_10/sequence_index_10.npz\n",
      "2023-04-12 15:12:14,726 - __main__ - INFO - Uploading to s3: dissertation-data-dmiller/torch_ready_data/files_used_10/sequence_index_10.npz\n",
      "2023-04-12 15:12:24,017 - __main__ - INFO - Sessionize complete for sequences [10]\n",
      "2023-04-12 15:12:24,021 - __main__ - INFO - Starting sessionize_users_cpu.py with arguments\n",
      "2023-04-12 15:12:24,022 - __main__ - INFO - {'data_subset': 30}\n",
      "2023-04-12 15:12:24,023 - __main__ - INFO - Reading data from calculated_features/files_used_30\n",
      "2023-04-12 15:12:30,643 - __main__ - INFO - Data read: (38500990, 32)\n",
      "2023-04-12 15:12:30,644 - __main__ - INFO - Casting date time and sorting by date time\n",
      "2023-04-12 15:12:30,708 - __main__ - INFO - Data read: scaling scaler columns\n",
      "2023-04-12 15:12:38,177 - __main__ - INFO - Scaling complete: implement sessionize\n",
      "2023-04-12 15:12:38,178 - __main__ - INFO - Generating sequence for 10\n",
      "2023-04-12 15:12:38,179 - __main__ - INFO - Generating shifted clickstreams from 1 -> 11\n",
      "2023-04-12 15:12:38,194 - __main__ - INFO - Loading sequence: 1 -> 11\n",
      "2023-04-12 15:12:41,044 - __main__ - INFO - Loading sequence: 2 -> 11\n",
      "2023-04-12 15:12:43,830 - __main__ - INFO - Loading sequence: 3 -> 11\n",
      "2023-04-12 15:12:46,700 - __main__ - INFO - Loading sequence: 4 -> 11\n",
      "2023-04-12 15:12:49,554 - __main__ - INFO - Loading sequence: 5 -> 11\n",
      "2023-04-12 15:12:52,368 - __main__ - INFO - Loading sequence: 6 -> 11\n",
      "2023-04-12 15:12:55,187 - __main__ - INFO - Loading sequence: 7 -> 11\n",
      "2023-04-12 15:12:58,030 - __main__ - INFO - Loading sequence: 8 -> 11\n",
      "2023-04-12 15:13:00,813 - __main__ - INFO - Loading sequence: 9 -> 11\n",
      "2023-04-12 15:13:03,589 - __main__ - INFO - Loading sequence: 10 -> 11\n",
      "2023-04-12 15:13:06,543 - __main__ - INFO - Shifter shape: torch.Size([38500990, 180])\n",
      "2023-04-12 15:13:06,544 - __main__ - INFO - Loading intial clickstream to cuda\n",
      "2023-04-12 15:13:06,544 - __main__ - INFO - Initial clickstream writing to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 32% |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 15:13:06,852 - __main__ - INFO - Saving to disk: torch_ready_data/files_used_30/sequence_index_0.npz\n",
      "2023-04-12 15:15:16,080 - __main__ - INFO - Uploading to s3: dissertation-data-dmiller/torch_ready_data/files_used_30/sequence_index_0.npz\n",
      "2023-04-12 15:15:45,899 - __main__ - INFO - Writing sequence to disk: 10\n",
      "2023-04-12 15:15:54,906 - __main__ - INFO - Saving to disk: torch_ready_data/files_used_30/sequence_index_10.npz\n",
      "2023-04-12 15:18:40,342 - __main__ - INFO - Uploading to s3: dissertation-data-dmiller/torch_ready_data/files_used_30/sequence_index_10.npz\n",
      "2023-04-12 15:19:10,294 - __main__ - INFO - Sessionize complete for sequences [10]\n"
     ]
    }
   ],
   "source": [
    "class Arguments:\n",
    "    seq_list = [10]\n",
    "    input_path = 'calculated_features'\n",
    "    output_path = 'torch_ready_data'\n",
    "    data_subset = 10\n",
    "    save_s3 = True\n",
    "\n",
    "for data_subset in [2, 10, 30]:\n",
    "    args = Arguments()\n",
    "    args.data_subset = data_subset\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r torch_ready_data_main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1da7ff4cdcccf44e7e228c52b231f7d5c5854d5618af555ed3871fd5cba609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
