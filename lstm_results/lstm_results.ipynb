{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "import plotly\n",
    "import plotly.offline as pyo\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pio.renderers.default = 'notebook+pdf'\n",
    "\n",
    "PLOTLY_COLORS = plotly.colors.DEFAULT_PLOTLY_COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BASE_DIR = 's3://dissertation-data-dmiller'\n",
    "\n",
    "SEQ_CONTAINER_EXP_10 = {\n",
    "    'LSTM SEQ 1':  os.path.join(S3_BASE_DIR,'lstm-experiments/ordinal-sequence-length-10-window-1/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 10': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-10-window-10/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 20': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-20-window-10/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 30': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-30-window-10/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 40': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-40-window-20/lightning_logs/version_1'),\n",
    " }\n",
    "\n",
    "SEQ_CONTAINER_EXP_20 = {\n",
    "    'LSTM SEQ 1':  os.path.join(S3_BASE_DIR,'lstm-experiments/ordinal-sequence-length-1-window-20/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 10': os.path.join(S3_BASE_DIR,'lstm-experiments/ordinal-sequence-length-10-window-20/lightning_logs/version_1'),\n",
    "    'LSTM SEQ 20': os.path.join(S3_BASE_DIR,'lstm-experiments/ordinal-sequence-length-20-window-10/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 30': os.path.join(S3_BASE_DIR,'lstm-experiments/ordinal-sequence-length-30-window-20/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 40': os.path.join(S3_BASE_DIR,'lstm-experiments/ordinal-sequence-length-30-window-20/lightning_logs/version_0'),\n",
    "}  \n",
    "\n",
    "SEQ_CONTAINER_EXP_30 = {\n",
    "    'LSTM SEQ 1': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-10/lightning_logs/version_3'),\n",
    "    'LSTM SEQ 10': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-10/lightning_logs/version_1'),\n",
    "    'LSTM SEQ 20': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-20/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 30': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-30/lightning_logs/version_0'),\n",
    "    'LSTM SEQ 30 H': os.path.join(S3_BASE_DIR, 'lstm-experiments/heuristic-ordinal-sequence-length-30/lightning_logs/version_8'),\n",
    "    'LSTM SEQ 40': os.path.join(S3_BASE_DIR, 'lstm-experiments/ordinal-sequence-length-40/lightning_logs/version_0')\n",
    "}\n",
    "\n",
    "METRIC_MATRIX = {\n",
    "    'losses': ['train_loss_e', 'val_loss_e', 'Model', 'Experiment'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_metrics_from_tensorboard(event_acc, scalar):\n",
    "    train_metrics, val_metrics = event_acc.Scalars(f'{scalar}/train'), event_acc.Scalars(f'{scalar}/valid')\n",
    "    train_df, val_df = pd.DataFrame(train_metrics), pd.DataFrame(val_metrics)\n",
    "\n",
    "    train_df.drop(columns=['wall_time'], inplace=True)\n",
    "    val_df.drop(columns=['wall_time'], inplace=True)\n",
    "\n",
    "    train_df.rename(columns={'value': f'train_{scalar}'}, inplace=True)\n",
    "    val_df.rename(columns={'value': f'val_{scalar}'}, inplace=True)\n",
    "    results = pd.merge(train_df, val_df, on='step', how='outer')\n",
    "    results = results.dropna()\n",
    "    results = results.drop(columns=['step'])\n",
    "    return results\n",
    "\n",
    "def top_metrics(results):\n",
    "    metric_container = []\n",
    "    for experiment_name, df in results.items():\n",
    "        metric_container.append(_best_metrics(df, experiment_name))\n",
    "    \n",
    "    return pd.DataFrame(metric_container)\n",
    "\n",
    "def tensorboard_results(log_dir, experiment_name):\n",
    "\n",
    "    loss_list, acc_list, prec_list, rec_list = [], [], [], []\n",
    "\n",
    "    events = EventAccumulator(log_dir)\n",
    "    events.Reload()\n",
    "        \n",
    "    loss_list.append(_get_metrics_from_tensorboard(events, 'loss_e'))\n",
    "    acc_list.append(_get_metrics_from_tensorboard(events, 'acc'))\n",
    "    prec_list.append(_get_metrics_from_tensorboard(events, 'prec'))\n",
    "    rec_list.append(_get_metrics_from_tensorboard(events, 'rec'))\n",
    "\n",
    "    loss, acc, prec, rec = (\n",
    "        pd.concat(loss_list).reset_index().drop(columns=['index']),\n",
    "        pd.concat(acc_list).reset_index().drop(columns=['index']),\n",
    "        pd.concat(prec_list).reset_index().drop(columns=['index']),\n",
    "        pd.concat(rec_list).reset_index().drop(columns=['index'])\n",
    "    )\n",
    "   \n",
    "    out_df = pd.concat([loss, acc, prec, rec], axis=1)\n",
    "    out_df['Model'] = experiment_name \n",
    "    return out_df\n",
    "\n",
    "def _best_metrics(df, name):\n",
    "\n",
    "    # last row from columns\n",
    "    return {\n",
    "        'Experiment': name,\n",
    "        'BCE Loss Train': df['train_loss_e'].iloc[-1].round(4),\n",
    "        'BCE Loss': df['val_loss_e'].iloc[-1].round(4),\n",
    "        'Accuracy': df['val_acc'].iloc[-1].round(4),\n",
    "        'Precision': df['val_prec'].iloc[-1].round(4),\n",
    "        'Recall': df['val_rec'].iloc[-1].round(4),\n",
    "    }\n",
    "\n",
    "def combine_subsets(df_matrix, col_subset, exp):\n",
    "    model_container = []\n",
    "    for model, df in df_matrix.items():\n",
    "        model_subset = df[col_subset]\n",
    "        model_container.append(model_subset)\n",
    "\n",
    "    \n",
    "    out_df = pd.concat(model_container)\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def tf_to_disk(seq_container, exp):\n",
    "    tf_matrix = {\n",
    "        k: tensorboard_results(v, k) for k, v in seq_container.items()\n",
    "    }\n",
    "    \n",
    "    for f_name, df in tf_matrix.items():\n",
    "        f_out = re.sub(r'[^a-zA-Z0-9]', '_', f_name).lower()\n",
    "        if not os.path.exists(os.path.join('result_csv', f'result_csv_{exp}')):\n",
    "            os.makedirs(os.path.join('result_csv', f'result_csv_{exp}')) \n",
    "        df.to_csv(os.path.join('result_csv', f'result_csv_{exp}', f'{f_out}.csv'), index=False)\n",
    "\n",
    "        \n",
    "def generate_metrics(exp):\n",
    "    \n",
    "    path = os.path.join('result_csv', f'result_csv_{exp}')\n",
    "    metric_container = {\n",
    "        re.sub(r'[^a-zA-Z0-9]', ' ', f_name).upper().replace('CSV', '').strip(): pd.read_csv(os.path.join(path, f_name)) for f_name in os.listdir(path)\n",
    "    }\n",
    "    \n",
    "    for k, v in metric_container.items():\n",
    "        v['Experiment'] = exp\n",
    "        metric_container[k] = v\n",
    "    return metric_container\n",
    "\n",
    "\n",
    "def metric_to_disk(file_sub_list, metric):\n",
    "    file_matrix = []\n",
    "    for file_sub in file_sub_list:\n",
    "        files = generate_metrics(file_sub)\n",
    "        file_matrix.append(combine_subsets(files, METRIC_MATRIX[metric], file_sub))\n",
    "    \n",
    "    df = pd.concat(file_matrix)\n",
    "    df.to_csv(os.path.join('result_csv', f'result_csv_{metric}.csv'), index=False)\n",
    "    \n",
    "\n",
    "def plot_graph(df, subset, exp, title):\n",
    "    df = df[df['Experiment'] == exp]\n",
    "    df = df[subset]\n",
    "    fig = px.line(df, x='step', y='train_loss_e' if 'Training' in title else 'val_loss_e', color='Model', line_group='Model')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='BCE Loss',\n",
    "        width=800,\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    # fig.show()\n",
    "    \n",
    "    path = os.path.join('lstm_plots', f'lstm_plots_{exp}', f'loss_{\"train\" if \"Training\" in title else \"val\"}.png')\n",
    "    fig.write_image(path)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_to_disk(SEQ_CONTAINER_EXP_10, 10)\n",
    "# tf_to_disk(SEQ_CONTAINER_EXP_20, 20)\n",
    "# tf_to_disk(SEQ_CONTAINER_EXP_30, 30)\n",
    "# metric_to_disk([10, 20, 30], 'losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.read_csv('result_csv/result_csv_losses.csv')\n",
    "losses['step'] = losses.groupby(['Model', 'Experiment']).cumcount()\n",
    "losses = losses[losses['step'] < 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_sub in [10, 20, 30]:\n",
    "    plot_graph(losses, ['step', 'train_loss_e', 'val_loss_e', 'Model', 'Experiment'], graph_sub, 'Training BCE Loss')\n",
    "    plot_graph(losses, ['step', 'train_loss_e', 'val_loss_e', 'Model', 'Experiment'], graph_sub, 'Validation BCE Loss')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d416da14fbf87d60bee8fe1b0b7ddcc23cfc0b1fdf2dc425f252bb8a1f4761b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
